{
 "cells": [
  {
   "cell_type": "raw",
   "id": "14977925-c414-4412-accc-833a51164e6c",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Handling Missing Values\"\n",
    "author: \"Kashish Mukheja\"\n",
    "date: \"2023-05-27\"\n",
    "categories: [blogging, jupyter, Data Preprocessing]\n",
    "format:\n",
    "  html:\n",
    "    code-fold: false\n",
    "    code-summary: \"Show the code\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6661324-1328-4494-9fdf-57868d16c299",
   "metadata": {},
   "source": [
    "## This blog focuses on handling missing values in the dataframe. \n",
    "\n",
    "A dataset can have columns containing null values, and these arise from 3 reasons : (1) Missing Complete at Random, (2) Missing at Random, (3) Missing Not at Random. Null values in *case of (1) and (2)* are not useful for insights and inferences, and should be replaced/imputed with some other value. The *some other value* depends on multiple factors. We will focus on numerical and categorical columns with missing values as part of the current blog."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6034515a-fb18-4484-8deb-a5666c65b778",
   "metadata": {},
   "source": [
    "We can hanlde missing values by any of the below techniques:\n",
    "\n",
    "1. Dropping rows or columns - This can lead to missing out of valuable information in the data. Most often, not a suggested approach. Listwise Deletion, is another form of dropping rows containing missing values.  \n",
    "\n",
    "2. Replacing missing values with mean or median, i.e., P50 (for continuous data) - Effect of outliers will can play a role in replacing with mean. Replacing the values with median, is a good option.\n",
    "\n",
    "3. Replacing missing values with mode (for categorical) - This is only for categorical , and may or may not work depending on the dataset you're dealing with. This completely ignores the affect of features (i.e., feature importance and tree interpretation) have on the target variables.\n",
    "\n",
    "4. Replacing missing values using KNN model -  The k nearest neighbor algorithm is often used to impute a missing value based on how closely it resembles the points in the training set. The non-null features are used to predict the features having null values\n",
    "\n",
    "5. MultiVariate Imputation - It suggests imputing the null values based on the other columns in the dataset. It therefore assumes that data (or features) with missing values have some sort of relation with the non-missing feature columns. This is also called Multiple Imputation by Chained Equation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b3801c-7326-49b9-95fb-efe7d2a126c7",
   "metadata": {},
   "source": [
    "# References:\n",
    "\n",
    "1. https://medium.com/analytics-vidhya/a-beginners-guide-to-multivariate-imputation-fe4ae5591544\n",
    "2. https://pub.towardsai.net/handling-missing-data-for-advanced-machine-learning-b6eb89050357 \n",
    "3. https://www.numpyninja.com/post/mice-and-knn-missing-value-imputations-through-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5da2766-0873-4ac5-9f0e-e91d356131d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
