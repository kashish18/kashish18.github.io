[
  {
    "objectID": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html",
    "href": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html",
    "title": "Encoding Columns in a DataFrame",
    "section": "",
    "text": "There are several blogs already present that provide detail on OneHotEncoding, LabelEncoding, etc. This blog will strictly focus on Encoding 1 or multiple columns of the dataframe in a single go. To achieve this, we use sklearn’s ColumnTransformer API.\nLet’s start with Installing the necessary libraries.."
  },
  {
    "objectID": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html#this-blog-focuses-on-encoding-columns-in-a-dataframe",
    "href": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html#this-blog-focuses-on-encoding-columns-in-a-dataframe",
    "title": "Encoding Columns in a DataFrame",
    "section": "",
    "text": "There are several blogs already present that provide detail on OneHotEncoding, LabelEncoding, etc. This blog will strictly focus on Encoding 1 or multiple columns of the dataframe in a single go. To achieve this, we use sklearn’s ColumnTransformer API.\nLet’s start with Installing the necessary libraries.."
  },
  {
    "objectID": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html#installing-libraries",
    "href": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html#installing-libraries",
    "title": "Encoding Columns in a DataFrame",
    "section": "Installing Libraries",
    "text": "Installing Libraries\n\nimport pandas as pd\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OrdinalEncoder, OneHotEncoder"
  },
  {
    "objectID": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html#lets-create-a-dummy-dataframe",
    "href": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html#lets-create-a-dummy-dataframe",
    "title": "Encoding Columns in a DataFrame",
    "section": "Let’s create a dummy dataframe",
    "text": "Let’s create a dummy dataframe\nWe will create a dataframe name employee_df with columns field, salary, avg_years_of_exp, and gender_category. Column gender_category will have one of either Male/Female whichever has the highest proportion in that particular field.\n\nemployees_df = pd.DataFrame({\n    'field': ['Tech', 'Finance', 'HR', 'Marketing', 'Sales','BioTech'],\n    'salary': ['high', 'high', 'low', 'medium', 'medium', 'high'],\n    'avg_years_of_exp': [4, 6, 5, 8, 8, 10],\n    'gender_category': ['Male', 'Female', 'Female', 'Male', 'Male', 'Female'], # max(Male, Female) gender for each field  \n})\n\n\nfield, and gender_category are non-ordinal categorical features\nsalary is an ordinal categorical feature\navg_years_of_exp looks like a categorical feature as well, but when considering the bigger picture, where we would have thousands of records, and maybe in floating point data types, will not be treated as a categorical feature. We can create a year_experice_range column containing different range of experience (For E.g., 0-3, 4-6, etc.) and treat that as a categorical feature. But we will ignore that for now."
  },
  {
    "objectID": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html#creating-ordinal-feature-and-ordinalencoder",
    "href": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html#creating-ordinal-feature-and-ordinalencoder",
    "title": "Encoding Columns in a DataFrame",
    "section": "Creating Ordinal Feature and OrdinalEncoder",
    "text": "Creating Ordinal Feature and OrdinalEncoder\nOrdinal related to a column which can be thought of as a categorical one, but with a maintained sequencing or hierarchy. For instance, (1) Rank 1,2, or 3 ; (2) Salary as high, low, or medium; (3) height as tall, taller, tallest and so on.\n\nordinal_feature = ['salary']\nordinal_transformer = OrdinalEncoder()"
  },
  {
    "objectID": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html#creating-non-ordinal-feature-and-onehotencoder",
    "href": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html#creating-non-ordinal-feature-and-onehotencoder",
    "title": "Encoding Columns in a DataFrame",
    "section": "Creating Non Ordinal Feature and OneHotEncoder",
    "text": "Creating Non Ordinal Feature and OneHotEncoder\n\nnon_ordinal_categorical_features = ['field', 'gender_category']\nnon_ordinal_categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")"
  },
  {
    "objectID": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html#creating-column-transformer",
    "href": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html#creating-column-transformer",
    "title": "Encoding Columns in a DataFrame",
    "section": "Creating Column Transformer",
    "text": "Creating Column Transformer\nWe provide data for ordinal_transformer & non_ordinal_categorical_transformer\n\ncolumn_transformer = ColumnTransformer(transformers=[\n    ('ordinal', ordinal_transformer, ordinal_feature),\n    ('non_ordinal_category', non_ordinal_categorical_transformer, non_ordinal_categorical_features)],\n                                      remainder='drop')\n\n\nremainder='drop' will drop all the remaining columns which do not required to be transformed. If you want to keep the remaining columns as it is, you may provide remainder='passthrough\n\n\npd.DataFrame(column_transformer.fit_transform(employees_df))\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n\n0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n1.0\n\n\n1\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n2\n1.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n3\n2.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n1.0\n\n\n4\n2.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n1.0\n\n\n5\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n\n\n\n\n\nAs you can see, we are not really able to comprehend which column represents what value from the original dataframe. To compensate for it, we will just perform a couple of tweeks."
  },
  {
    "objectID": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html#creating-the-final-transformer-with-columns-intact-and-understandable",
    "href": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html#creating-the-final-transformer-with-columns-intact-and-understandable",
    "title": "Encoding Columns in a DataFrame",
    "section": "Creating the final Transformer with Columns intact and understandable",
    "text": "Creating the final Transformer with Columns intact and understandable\n\nnon_ordinal_categorical_transformer = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\") # New code added\n\n# Note: sparse_output=False is required to preserve column orders and provide a prefix for the columns. \n\ncolumn_transformer = ColumnTransformer(transformers=[\n    ('ordinal', ordinal_transformer, ordinal_feature),\n    ('non_ordinal_category', non_ordinal_categorical_transformer, non_ordinal_categorical_features)],\n                                      remainder='drop') # This remains same\n\ncolumn_transformer.set_output(transform='pandas') # New code added\n\nColumnTransformer(transformers=[('ordinal', OrdinalEncoder(), ['salary']),\n                                ('non_ordinal_category',\n                                 OneHotEncoder(handle_unknown='ignore',\n                                               sparse_output=False),\n                                 ['field', 'gender_category'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.ColumnTransformerColumnTransformer(transformers=[('ordinal', OrdinalEncoder(), ['salary']),\n                                ('non_ordinal_category',\n                                 OneHotEncoder(handle_unknown='ignore',\n                                               sparse_output=False),\n                                 ['field', 'gender_category'])])ordinal['salary']OrdinalEncoderOrdinalEncoder()non_ordinal_category['field', 'gender_category']OneHotEncoderOneHotEncoder(handle_unknown='ignore', sparse_output=False)\n\n\n\ndf_pandas = column_transformer.fit_transform(employees_df)\ndf_pandas\n\n\n\n\n\n\n\n\nordinal__salary\nnon_ordinal_category__field_BioTech\nnon_ordinal_category__field_Finance\nnon_ordinal_category__field_HR\nnon_ordinal_category__field_Marketing\nnon_ordinal_category__field_Sales\nnon_ordinal_category__field_Tech\nnon_ordinal_category__gender_category_Female\nnon_ordinal_category__gender_category_Male\n\n\n\n\n0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n1.0\n\n\n1\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n2\n1.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n3\n2.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n1.0\n\n\n4\n2.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n1.0\n\n\n5\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0"
  },
  {
    "objectID": "posts/Data-preprocessing-Feature-Engineering/index.html",
    "href": "posts/Data-preprocessing-Feature-Engineering/index.html",
    "title": "Handling Missing Values",
    "section": "",
    "text": "A dataset can have columns containing null values, and these arise from 3 reasons : (1) Missing Complete at Random, (2) Missing at Random, (3) Missing Not at Random. Null values in case of (1) and (2) are not useful for insights and inferences, and should be replaced/imputed with some other value. The some other value depends on multiple factors. We will focus on numerical and categorical columns with missing values as part of the current blog.\nWe can hanlde missing values by any of the below techniques:\n\nDropping rows or columns - This can lead to missing out of valuable information in the data. Most often, not a suggested approach. Listwise Deletion, is another form of dropping rows containing missing values.\nReplacing missing values with mean or median, i.e., P50 (for continuous data) - Effect of outliers will can play a role in replacing with mean. Replacing the values with median, is a good option.\nReplacing missing values with mode (for categorical) - This is only for categorical , and may or may not work depending on the dataset you’re dealing with. This completely ignores the affect of features (i.e., feature importance and tree interpretation) have on the target variables.\nReplacing missing values using KNN model - The k nearest neighbor algorithm is often used to impute a missing value based on how closely it resembles the points in the training set. The non-null features are used to predict the features having null values\nMultiVariate Imputation - It suggests imputing the null values based on the other columns in the dataset. It therefore assumes that data (or features) with missing values have some sort of relation with the non-missing feature columns. This is also called Multiple Imputation by Chained Equation."
  },
  {
    "objectID": "posts/Data-preprocessing-Feature-Engineering/index.html#this-blog-focuses-on-handling-missing-values-in-the-dataframe.",
    "href": "posts/Data-preprocessing-Feature-Engineering/index.html#this-blog-focuses-on-handling-missing-values-in-the-dataframe.",
    "title": "Handling Missing Values",
    "section": "",
    "text": "A dataset can have columns containing null values, and these arise from 3 reasons : (1) Missing Complete at Random, (2) Missing at Random, (3) Missing Not at Random. Null values in case of (1) and (2) are not useful for insights and inferences, and should be replaced/imputed with some other value. The some other value depends on multiple factors. We will focus on numerical and categorical columns with missing values as part of the current blog.\nWe can hanlde missing values by any of the below techniques:\n\nDropping rows or columns - This can lead to missing out of valuable information in the data. Most often, not a suggested approach. Listwise Deletion, is another form of dropping rows containing missing values.\nReplacing missing values with mean or median, i.e., P50 (for continuous data) - Effect of outliers will can play a role in replacing with mean. Replacing the values with median, is a good option.\nReplacing missing values with mode (for categorical) - This is only for categorical , and may or may not work depending on the dataset you’re dealing with. This completely ignores the affect of features (i.e., feature importance and tree interpretation) have on the target variables.\nReplacing missing values using KNN model - The k nearest neighbor algorithm is often used to impute a missing value based on how closely it resembles the points in the training set. The non-null features are used to predict the features having null values\nMultiVariate Imputation - It suggests imputing the null values based on the other columns in the dataset. It therefore assumes that data (or features) with missing values have some sort of relation with the non-missing feature columns. This is also called Multiple Imputation by Chained Equation."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/NLP/index.html",
    "href": "posts/NLP/index.html",
    "title": "NLP - Introduction",
    "section": "",
    "text": "Natural Language Processing involves fetching text data in the form of prose or document, and perform classification or other text-based applications. Some top applications include:\n\nSentiment Analysis\nWhich author wrote what document\nLegal Document discovery -&gt; Is the legal document in scope or out scope.\nOrganising documents -&gt;\nTriaging inbound emails -&gt; This involves routing of the incoming emails to the user or a work queue, to either handle the email, or taking actions in other ways to help address issues reported in the email\n\nWe are going to use HuggingFace Transformers library. It has a medium level API, and thus provides flexibility to tweak. The library has really state-of-the-art models (similar to Timm for Computer Vision). For the current blog, we will be using a Kaggle dataset for US Patent Phrase to Phrase matching.\nWe will fine tune a pre-trained hugging face model\nSeque: Huggingface models are different than Timm in the sense that each of the models in hugging face, can be trained on different corpuses for solving different problems.\nUsing different libraries, help brush up the same concepts in different ways. For the current blog, we will be using some of the standard python libraries like pandas, numpy, pytorch & for performing NLP specific operations, we will be using Huggingface transformer library. So let’s setup the noteboook first.."
  },
  {
    "objectID": "posts/NLP/index.html#something-about-the-ulm-fit",
    "href": "posts/NLP/index.html#something-about-the-ulm-fit",
    "title": "NLP - Introduction",
    "section": "Something about the ULM-Fit",
    "text": "Something about the ULM-Fit\nThe above concept, was first introduced in architecture called ULM-Fit , which was developed by Jeremy Howard. So, the idea of the architecture was:\n\nTrain a Language model using wikipedia pages, to predict every next word of every wikipedia article\nCreated a second language model, by using the first language model, and ran a few more epochs on IMDB movie reviews.\nUsed the model, and finally built a classifier to categorize movie rating\n\nJargon: A language model is something that can predict the next word in a text"
  },
  {
    "objectID": "posts/NLP/index.html#something-about-training-a-text-data",
    "href": "posts/NLP/index.html#something-about-training-a-text-data",
    "title": "NLP - Introduction",
    "section": "Something about training a text data",
    "text": "Something about training a text data\nNeural networks work with numbers. We take some numbers, multiple with matrices, replace the -ves with 0 (i.e., ReLU activation) and repeat the process a few times. But how would we do that for strings ? This is done in a few steps: 1. Split the text into tokens. Tokens are basically words or single unit of text. 2. After splitting into words, we get a unique number for each unique word (called vocabulary). The bigger the vocabulary, more data we will need to train, and thus more storage will be occupied, leading to reduced computation. We don’t want that right :)\nFurthermore, some languages like Chinese don’t have spaces in between words. So, to overcome this problem, we tokenise into subwords (which is not heavily dependent on spaces). So, instead of dividing the corpuse based on spaces, subwords tokenization perform seperation based on group of characters that occur frequently together, and these become the vocabulary.\nNow, this tokenisation has different algorithms depending on the pre-trained models we use. Basically, how we tokenise a data ? -&gt; Every model has its own unique way to tokenise."
  },
  {
    "objectID": "posts/Computer-Vision-Concepts/index.html",
    "href": "posts/Computer-Vision-Concepts/index.html",
    "title": "Computer Vision - Concepts",
    "section": "",
    "text": "Pixel is the smallest fragment of an image."
  },
  {
    "objectID": "posts/Computer-Vision-Concepts/index.html#a-simple-cnn-architecture",
    "href": "posts/Computer-Vision-Concepts/index.html#a-simple-cnn-architecture",
    "title": "Computer Vision - Concepts",
    "section": "A Simple CNN Architecture",
    "text": "A Simple CNN Architecture\n\nWhat is inside a single convolution layer ?\n\nImage (RGB channels) is multiplied with (2) Kernel/Filters to produce a (3) convoluted matrix, also called feature map. This matrix is passed (4) to an activation function like ReLU to create an activation map, and (5) Pooling is applied on the resultant matrix. This new feature map will be input to the 2nd convolution layer.\n\nOnce the image has gone through N Convolution layers, it is flattened to feed into the fully connected neural network, which will then perform classification. Here, the learnable parameters weights are Filters. So, the filter weights are updated during backpropagation.\n\n\nWhat is Transfer Learning ?\nModel utilising the knowledge of a pre-trained model (which was trained for a task), to train a new similar task. Popularly used in both CNN, & NLP.\n\n\nShow the code\n%%latex\n\\begin{align}\n\\nabla \\cdot \\vec{\\mathbf{E}} & = 4 \\pi \\rho \\\\\n\\nabla \\times \\vec{\\mathbf{E}}\\, +\\, \\frac1c\\, \\frac{\\partial\\vec{\\mathbf{B}}}{\\partial t} & = \\vec{\\mathbf{0}} \\\\\n\\nabla \\cdot \\vec{\\mathbf{B}} & = 0\n\\end{align}\n\n\n\\[\\begin{align}\n\\nabla \\cdot \\vec{\\mathbf{E}} & = 4 \\pi \\rho \\\\\n\\nabla \\times \\vec{\\mathbf{E}}\\, +\\, \\frac1c\\, \\frac{\\partial\\vec{\\mathbf{B}}}{\\partial t} & = \\vec{\\mathbf{0}} \\\\\n\\nabla \\cdot \\vec{\\mathbf{B}} & = 0\n\\end{align}\\]\n\n\n\n\nShow the code\n9\n\n\n9\n\n\n\n\nShow the code\n%%latex\n\\begin{align}\n\\mathbf{B} & = 0\n\\end{align}\n\n\n\\[\\begin{align}\n\\{B} & = 0\n\\end{align}\\]"
  },
  {
    "objectID": "posts/HuggingFace/Untitled1.html",
    "href": "posts/HuggingFace/Untitled1.html",
    "title": "kashish18.github.io",
    "section": "",
    "text": "import torch\n\n\nfrom diffusers import StableDiffusionPipeline\n\nDEVICE='mps'\n\npipe = StableDiffusionPipeline.from_pretrained(\n    \"CompVis/stable-diffusion-v1-4\",\n    # use_auth_token=True,\n    # revision=\"fp16\", \n    torch_dtype=torch.float16,\n    # safety_checker=None\n).to(torch.device(\"mps\"))\n\n`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n\n\n\npipe.to(torch.device(\"mps\")).enable_attention_slicing()\n\n\nprompt=\"a photograph of an astronaut riding a horse\"\n\n\npipe(prompt=prompt).images[0]\n\n\n\n\n\n\n\n\nprint(image)\n\n&lt;PIL.Image.Image image mode=RGB size=512x512 at 0x28394B690&gt;\n\n\n\nimage.show(title=\"Heya\")\n\n\n!ls ~/.cache/huggingface/hub\n\nmodels--CompVis--stable-diffusion-v1-4 version_diffusers_cache.txt\nversion.txt\n\n\n\npipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", revision=\"fp16\", torch_dtype=torch.float16).to(\"cuda\")"
  },
  {
    "objectID": "posts/HuggingFace/Untitled.html",
    "href": "posts/HuggingFace/Untitled.html",
    "title": "Hugging Face - Stable Diffusion",
    "section": "",
    "text": "Let’s first start with installing the diffusers library, which will be used for the entire notebook for image generation.\nShow the code\n!pip install -Uq diffusers transformers fastcore"
  },
  {
    "objectID": "posts/HuggingFace/Untitled.html#the-stable-diffusion-pipeline",
    "href": "posts/HuggingFace/Untitled.html#the-stable-diffusion-pipeline",
    "title": "Hugging Face - Stable Diffusion",
    "section": "The Stable Diffusion Pipeline",
    "text": "The Stable Diffusion Pipeline\nStable Diffusion has something called a Pipeline[1]. If you’re familiar with fast.ai, this is similar to what we call as fastai learner. The pipeline basically contains all the models, processing, inferencing, etc. One can save the pipeline, into the huggingface cloud (also called Hub). Learn more about diffusion inference pipeline[2].\nYou can start generating images with very few lines of code. One just need to provide the pre-trained model as repo-id present in the huggingface repo or a path t odirectory containing pipeline weights, train further and generate images of your choice. You can also save your own pipeline to the hub, for other people to use.\nSegue\n[1]. Many Hugging Face libraries (along with other libraries such as scikit-learn) use the concept of a “pipeline” to indicate a sequence of steps that when combined complete some task.\n[2]. Inference means, using the model to generate output (i.e., images here), as opposed to training (or fine-tuning) models using new data.\n\n\nShow the code\nDEVICE='mps'\n\npipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", use_auth_token=True).to(DEVICE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom_pretrained is used to create, and download the pipeline with pre-defined weights. This will download a few GBs of data. The weights are cached the first time we run the cell.\nfp16 also called half-precision floating point-numbers (i.e., float16). It occupies 16 bits (two bytes in modern computers) in computer memory. Read more here.\npipe.to(\"mps\") is used, if you’re working on a Mac machine with M1/M2 chip.\n\nWe use from_pretrained to create the pipeline and download the pretrained weights. We indicate that we want to use the fp16 (half-precision) version of the weights, and we tell diffusers to expect the weights in that format. This allows us to perform much faster inference with almost no discernible difference in quality.\n\n\nShow the code\n!!ls ~/.cache/huggingface/hub\n\n\n['\\x1b[1m\\x1b[36mmodels--CompVis--stable-diffusion-v1-4\\x1b[m\\x1b[m',\n 'version.txt',\n 'version_diffusers_cache.txt']\n\n\n\n\nShow the code\npipe.enable_attention_slicing()\n\n\n\n\nShow the code\nprompt = \"a photograph of an astronaut riding a tiger\"\n\n\n\n\nShow the code\npipe(prompt).images[0]\n\n\n\n\n\nKeyboardInterrupt: \n\n\n\n\nShow the code\n_ = pipe(prompt, num_inference_steps=1)\n\n\n\n\nShow the code\ntorch.__version__\n\n\n'2.0.0'\n\n\n\n\nShow the code\ntorch.has_mps\n\n\nTrue\n\n\n\n\nShow the code\ndevice = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.has_mps else \"cpu\"\nif torch.has_mps:\n    pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=True).to(device)\nelse:\n    pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", use_auth_token=True).to(device)\n\n\n/Users/kashmkj/micromamba/envs/fastai/lib/python3.11/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n  warnings.warn(\n\n\n\n\nShow the code\nimage = pipe(\"An astronaught scuba diving\").images[0]\n\n\n\n\nShow the code\ndevice = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.has_mps else \"cpu\"\nif torch.has_mps:\n    pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\").to(device)\n\n\n\n\nShow the code\n!ls ~/.cache/huggingface/hub\n\n\nmodels--CompVis--stable-diffusion-v1-4 version_diffusers_cache.txt\nversion.txt\n\n\n\n\nShow the code\npipe.enable_attention_slicing()\n\n\n\n\nShow the code\nprompt = \"a photograph of an astronaut riding a horse\"\n\n\n\n\nShow the code\npipe(prompt).images[0]\n\n\n\n\n\n\n\n\n\n\nShow the code\ntorch.manual_seed(1024)\n\n\n&lt;torch._C.Generator at 0x127d48810&gt;\n\n\n\n\nShow the code\npipe(prompt).images[0]\n\n\n\n\n\n\n\n\n\n\nShow the code\npipe.enable_attention_slicing()\npipe(prompt, num_inference_steps=3).images[0]\n\n\n\n\n\n\n\n\n\n\nShow the code\npipe\n\n\nStableDiffusionPipeline {\n  \"_class_name\": \"StableDiffusionPipeline\",\n  \"_diffusers_version\": \"0.18.2\",\n  \"feature_extractor\": [\n    \"transformers\",\n    \"CLIPImageProcessor\"\n  ],\n  \"requires_safety_checker\": true,\n  \"safety_checker\": [\n    \"stable_diffusion\",\n    \"StableDiffusionSafetyChecker\"\n  ],\n  \"scheduler\": [\n    \"diffusers\",\n    \"PNDMScheduler\"\n  ],\n  \"text_encoder\": [\n    \"transformers\",\n    \"CLIPTextModel\"\n  ],\n  \"tokenizer\": [\n    \"transformers\",\n    \"CLIPTokenizer\"\n  ],\n  \"unet\": [\n    \"diffusers\",\n    \"UNet2DConditionModel\"\n  ],\n  \"vae\": [\n    \"diffusers\",\n    \"AutoencoderKL\"\n  ]\n}\n\n\n\n\nShow the code\n!micromamba config --show channels\n\n\nThe following arguments were not expected: channels --show\nRun with --help for more information.\n\n\n\n\nShow the code\n!micromamba config list\n\n\nchannels:\n  - conda-forge\nauto_activate_base: false\n\n\n\n\nShow the code\n!micromamba install pytorch torchvision torchaudio -c pytorch-nightly -y\n\n\nconda-forge/osx-arm64                                       Using cache\nconda-forge/noarch                                          Using cache\n[+] 0.0s\n[+] 0.1s\npytorch-nightly/osx-arm64 ━━━━━━━━╸━━━━━━━━━   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\npytorch-nightly/noarch    ━━╸━━━━━━━━━━━━━━━   0.0 B /  ??.?MB @  ??.?MB/s  0.1s[+] 0.2s\npytorch-nightly/osx-arm64 ━━━━━━━━━━╸━━━━━━━   0.0 B /  ??.?MB @  ??.?MB/s  0.2s\npytorch-nightly/noarch    ━━━╸━━━━━━━━━━━━━━   0.0 B /  ??.?MB @  ??.?MB/s  0.2s[+] 0.3s\npytorch-nightly/osx-arm64 ━━━━━━━━━━╸━━━━━━━   0.0 B /  ??.?MB @  ??.?MB/s  0.3s\npytorch-nightly/noarch    ━━━╸━━━━━━━━━━━━━━   0.0 B /  ??.?MB @  ??.?MB/s  0.3s[+] 0.4s\npytorch-nightly/osx-arm64 ━━━━━━━━━━╸━━━━━━━   0.0 B /  ??.?MB @  ??.?MB/s  0.4s\npytorch-nightly/noarch    ━━━╸━━━━━━━━━━━━━━   0.0 B /  ??.?MB @  ??.?MB/s  0.4s[+] 0.5s\npytorch-nightly/osx-arm64 ━━━━━━━━━━╸━━━━━━━   0.0 B /  ??.?MB @  ??.?MB/s  0.5s\npytorch-nightly/noarch    ━━━╸━━━━━━━━━━━━━━   0.0 B /  ??.?MB @  ??.?MB/s  0.5spytorch-nightly/osx-arm64                            3.6kB @   6.3kB/s  0.6s\n[+] 0.6s\npytorch-nightly/noarch ━━━━━━╸━━━━━━━━━━━━━━   0.0 B /  ??.?MB @  ??.?MB/s  0.6s[+] 0.7s\npytorch-nightly/noarch ━━━━━━╸━━━━━━━━━━━━━━   0.0 B /  ??.?MB @  ??.?MB/s  0.7s[+] 0.8s\npytorch-nightly/noarch ━━━━━━╸━━━━━━━━━━━━━━   0.0 B /  ??.?MB @  ??.?MB/s  0.8s[+] 0.9s\npytorch-nightly/noarch ━━━━━━╸━━━━━━━━━━━━━━   0.0 B /  ??.?MB @  ??.?MB/s  0.9s[+] 1.0s\npytorch-nightly/noarch ━━━━━━╸━━━━━━━━━━━━━━   0.0 B /  ??.?MB @  ??.?MB/s  1.0s[+] 1.1s\npytorch-nightly/noarch ━━━━━━╸━━━━━━━━━━━━━━   0.0 B /  ??.?MB @  ??.?MB/s  1.1s[+] 1.2s\npytorch-nightly/noarch ━━━━━━╸━━━━━━━━━━━━━━   0.0 B /  ??.?MB @  ??.?MB/s  1.2s[+] 1.3s\npytorch-nightly/noarch ━━━━━━━╸━━━━━━━━━━━━━   0.0 B /  ??.?MB @  ??.?MB/s  1.3s[+] 1.4s\npytorch-nightly/noarch ━━━━━━━╸━━━━━━━━━━━━━   0.0 B /  ??.?MB @  ??.?MB/s  1.4s[+] 1.5s\npytorch-nightly/noarch ━━━━━━━╸━━━━━━━━━━━━━   0.0 B /  ??.?MB @  ??.?MB/s  1.5spytorch-nightly/noarch                               1.1kB @ 721.0 B/s  1.5s\n\nPinned packages:\n  - python 3.11.*\n\n\nTransaction\n\n  Prefix: /Users/kashmkj/micromamba/envs/fastai\n\n  Updating specs:\n\n   - pytorch\n   - torchvision\n   - torchaudio\n\n\nwarning  libmamba Extracted package cache '/Users/kashmkj/micromamba/pkgs/libdeflate-1.18-h1a8c8d9_0' has invalid url\nwarning  libmamba Extracted package cache '/Users/kashmkj/micromamba/pkgs/libjpeg-turbo-2.1.5.1-h1a8c8d9_0' has invalid url\nwarning  libmamba Extracted package cache '/Users/kashmkj/micromamba/pkgs/libwebp-base-1.3.0-h1a8c8d9_0' has invalid url\nwarning  libmamba Extracted package cache '/Users/kashmkj/micromamba/pkgs/lcms2-2.15-hd835a16_1' has invalid url\n  Package                     Version  Build                Channel               Size\n────────────────────────────────────────────────────────────────────────────────────────\n  Install:\n────────────────────────────────────────────────────────────────────────────────────────\n\n  + torchaudio      2.1.0.dev20230720  py311_cpu            pytorch-nightly        6MB\n  + jpeg                           9e  he4db4b2_2           conda-forge         Cached\n  + aom                         3.5.0  h7ea286d_0           conda-forge         Cached\n  + svt-av1                     1.4.1  h7ea286d_0           conda-forge         Cached\n  + libtasn1                   4.19.0  h1a8c8d9_0           conda-forge         Cached\n  + nettle                      3.8.1  h63371fa_1           conda-forge         Cached\n  + lame                        3.100  h1a8c8d9_1003        conda-forge         Cached\n  + libopus                     1.3.1  h27ca646_1           conda-forge          253kB\n  + libvpx                     1.11.0  hc470f4d_3           conda-forge         Cached\n  + openh264                    2.3.1  hb7217d7_2           conda-forge         Cached\n  + x264                   1!164.3095  h57fd34a_2           conda-forge         Cached\n  + x265                          3.5  hbc6ce65_3           conda-forge         Cached\n  + libunistring               0.9.10  h3422bc3_0           conda-forge         Cached\n  + p11-kit                    0.24.1  h29577a5_0           conda-forge         Cached\n  + libidn2                     2.3.4  h1a8c8d9_0           conda-forge         Cached\n  + gnutls                      3.7.8  h9f1a10d_0           conda-forge         Cached\n  + ffmpeg                      5.1.2  gpl_hf318d42_106     conda-forge            8MB\n\n  Change:\n────────────────────────────────────────────────────────────────────────────────────────\n\n  - libtiff                     4.5.0  h4f7d55c_6           conda-forge         Cached\n  + libtiff                     4.5.0  h5dffbdd_2           conda-forge          348kB\n  - gdk-pixbuf                2.42.10  h1ac0d0d_2           conda-forge         Cached\n  + gdk-pixbuf                2.42.10  h9bcf4fe_0           conda-forge          534kB\n  - lcms2                        2.15  hd835a16_1           fastchan            Cached\n  + lcms2                        2.15  h481adae_0           conda-forge          206kB\n  - libgd                       2.3.3  h939342b_6           conda-forge         Cached\n  + libgd                       2.3.3  h8db8f0b_5           conda-forge          199kB\n\n  Upgrade:\n────────────────────────────────────────────────────────────────────────────────────────\n\n  - pytorch                     2.0.0  cpu_py311hb4bb8ad_0  conda-forge         Cached\n  + pytorch         2.1.0.dev20230720  py3.11_0             pytorch-nightly       55MB\n  - torchvision                0.15.1  cpu_py311h98313cd_0  conda-forge         Cached\n  + torchvision    0.16.0.dev20230720  py311_cpu            pytorch-nightly        7MB\n\n  Downgrade:\n────────────────────────────────────────────────────────────────────────────────────────\n\n  - libdeflate                   1.18  h1a8c8d9_0           fastchan            Cached\n  + libdeflate                   1.17  h1a8c8d9_0           conda-forge           48kB\n  - libjpeg-turbo             2.1.5.1  h1a8c8d9_0           fastchan            Cached\n  + libjpeg-turbo               2.1.4  h1a8c8d9_0           conda-forge         Cached\n  - libwebp-base                1.3.0  h1a8c8d9_0           fastchan            Cached\n  + libwebp-base                1.2.4  h57fd34a_0           conda-forge          324kB\n  - libwebp                     1.3.0  h66d6964_0           conda-forge         Cached\n  + libwebp                     1.2.4  h999c80f_1           conda-forge           78kB\n  - pillow                      9.5.0  py311h979b395_0      fastchan            Cached\n  + pillow                      9.4.0  py311h627eb56_1      conda-forge           47MB\n  - graphviz                    8.0.5  h10878c0_0           fastchan            Cached\n  + graphviz                    7.1.0  h4f8fbd6_0           conda-forge            5MB\n\n  Summary:\n\n  Install: 17 packages\n  Change: 4 packages\n  Upgrade: 2 packages\n  Downgrade: 6 packages\n\n  Total download: 130MB\n\n────────────────────────────────────────────────────────────────────────────────────────\n\n\n\nTransaction starting\n[+] 0.0s\nDownloading      ━━━━━━━━━━━━━━━━━━━━━━━   0.0 B                            0.0s\nExtracting       ━━━━━━━━━━━━━━━━━━━━━━━       0                            0.0s[+] 0.1s\nDownloading  (5) ━━━━━━━━━╸━━━━━━━━━━━━━   0.0 B libdeflate                 0.0s\nExtracting       ━━━━━━━━━━━━━━━━━━━━━━━       0                            0.0s[+] 0.2s\nDownloading  (5) ━━━━━━━━━╸━━━━━━━━━━━━━   0.0 B libdeflate                 0.1s\nExtracting       ━━━━━━━━━━━━━━━━━━━━━━━       0                            0.0s[+] 0.3s\nDownloading  (5) ━━━━━━━━━╸━━━━━━━━━━━━━   0.0 B libdeflate                 0.2s\nExtracting       ━━━━━━━━━━━━━━━━━━━━━━━       0                            0.0s[+] 0.4s\nDownloading  (5) ━━━━━━━━━╸━━━━━━━━━━━━━   0.0 B libdeflate                 0.3s\nExtracting       ━━━━━━━━━━━━━━━━━━━━━━━       0                            0.0s[+] 0.5s\nDownloading  (5) ━━━━━━━━━╸━━━━━━━━━━━━━   0.0 B libopus                    0.4s\nExtracting       ━━━━━━━━━━━━━━━━━━━━━━━       0                            0.0s[+] 0.6s\nDownloading  (5) ━━━━━━━━━╸━━━━━━━━━━━━━  95.2kB libopus                    0.5s\nExtracting       ━━━━━━━━━━━━━━━━━━━━━━━       0                            0.0slibdeflate                                          48.2kB @  73.8kB/s  0.7s\nlibopus                                            252.9kB @ 369.2kB/s  0.7s\n[+] 0.7s\nDownloading  (5) ━━━━━━━━━━━━━━━━━━━╸━━━ 392.0kB libwebp-base               0.6s\nExtracting   (2) ━━━━━━━━━━━╸━━━━━━━━━━━       0 libdeflate                 0.0s[+] 0.8s\nDownloading  (5) ━━━━━━━━━━━━━━━━━━━╸━━━ 772.5kB libwebp-base               0.7s\nExtracting       ━━╸━━━━━━━━━━━━━━━━━━━━       2                            0.1s[+] 0.9s\nDownloading  (5) ━━━━━━━━━━━━━━━━━━━╸━━━   1.2MB libwebp-base               0.8s\nExtracting       ━━╸━━━━━━━━━━━━━━━━━━━━       2                            0.1s[+] 1.0s\nDownloading  (5) ━━━━━━━━━━━━━━━━━━━╸━━━   1.4MB libwebp-base               0.9s\nExtracting       ━━╸━━━━━━━━━━━━━━━━━━━━       2                            0.1s[+] 1.1s\nDownloading  (5) ━━━━━━━━━━━━━━━━━━━╸━━━   1.7MB pillow                     1.0s\nExtracting       ━━╸━━━━━━━━━━━━━━━━━━━━       2                            0.1s[+] 1.2s\nDownloading  (5) ━━━━━━━━━━━━━━━━━━━╸━━━   2.1MB pillow                     1.1s\nExtracting       ━━╸━━━━━━━━━━━━━━━━━━━━       2                            0.1s[+] 1.3s\nDownloading  (5) ━━━━━━━━━━━━━━━━━━━╸━━━   2.6MB pillow                     1.2s\nExtracting       ━━╸━━━━━━━━━━━━━━━━━━━━       2                            0.1s[+] 1.4s\nDownloading  (5) ━━━━━━━━━━━━━━━━━━━╸━━━   3.0MB pillow                     1.3s\nExtracting       ━━╸━━━━━━━━━━━━━━━━━━━━       2                            0.1s[+] 1.5s\nDownloading  (5) ━━━━━━━━━━━━━━━━━━━╸━━━   3.2MB pytorch                    1.4s\nExtracting       ━━╸━━━━━━━━━━━━━━━━━━━━       2                            0.1slibwebp-base                                       323.6kB @ 212.7kB/s  1.5s\n[+] 1.6s\nDownloading  (5) ━━━━━━━━━━━━━━━━━━━╸━━━   3.6MB pytorch                    1.5s\nExtracting       ━━━╸━━━━━━━━━━━━━━━━━━━       3                            0.1s[+] 1.7s\nDownloading  (5) ━━━━━━━━━━━━━━━━━━━╸━━━   4.0MB pytorch                    1.6s\nExtracting       ━━━╸━━━━━━━━━━━━━━━━━━━       3                            0.1s[+] 1.8s\nDownloading  (5) ━━━━━━━━━━━━━━━━━━━╸━━━   4.5MB pytorch                    1.7s\nExtracting       ━━━╸━━━━━━━━━━━━━━━━━━━       3                            0.1s[+] 1.9s\nDownloading  (5) ━━━━━━━━━━━━━━━━━━━╸━━━   5.0MB torchaudio                 1.8s\nExtracting       ━━━╸━━━━━━━━━━━━━━━━━━━       3                            0.1s[+] 2.0s\nDownloading  (5) ━━━━━━━━━━━━━━━━━━━╸━━━   5.1MB torchaudio                 1.9s\nExtracting       ━━━╸━━━━━━━━━━━━━━━━━━━       3                            0.1s[+] 2.1s\nDownloading  (5) ━━━━━━━━━━━━━━━━━━━╸━━━   5.9MB torchaudio                 2.0s\nExtracting       ━━━╸━━━━━━━━━━━━━━━━━━━       3                            0.1s[+] 2.2s\nDownloading  (5) ━━━━━━━━━━━━━━━━━━━╸━━━   5.9MB torchaudio                 2.1s\nExtracting       ━━━╸━━━━━━━━━━━━━━━━━━━       3                            0.1s[+] 2.3s\nDownloading  (5) ╸━━━━━━━━━━━━━━━━━━╸━━━   6.8MB torchvision                2.2s\nExtracting       ━━━╸━━━━━━━━━━━━━━━━━━━       3                            0.1s[+] 2.4s\nDownloading  (5) ╸━━━━━━━━━━━━━━━━━━╸━━━   7.4MB torchvision                2.3s\nExtracting       ━━━╸━━━━━━━━━━━━━━━━━━━       3                            0.1s[+] 2.5s\nDownloading  (5) ╸━━━━━━━━━━━━━━━━━━╸━━━   7.9MB torchvision                2.4s\nExtracting       ━━━╸━━━━━━━━━━━━━━━━━━━       3                            0.1s[+] 2.6s\nDownloading  (5) ╸━━━━━━━━━━━━━━━━━━╸━━━   8.2MB torchvision                2.5s\nExtracting       ━━━╸━━━━━━━━━━━━━━━━━━━       3                            0.1s[+] 2.7s\nDownloading  (5) ╸━━━━━━━━━━━━━━━━━━╸━━━   8.7MB gdk-pixbuf                 2.6s\nExtracting       ━━━╸━━━━━━━━━━━━━━━━━━━       3                            0.1s[+] 2.8s\nDownloading  (5) ╸━━━━━━━━━━━━━━━━━━╸━━━   9.1MB gdk-pixbuf                 2.7s\nExtracting       ━━━╸━━━━━━━━━━━━━━━━━━━       3                            0.1s[+] 2.9s\nDownloading  (5) ╸━━━━━━━━━━━━━━━━━━╸━━━   9.5MB gdk-pixbuf                 2.8s\nExtracting       ━━━╸━━━━━━━━━━━━━━━━━━━       3                            0.1s[+] 3.0s\nDownloading  (5) ╸━━━━━━━━━━━━━━━━━━╸━━━   9.9MB gdk-pixbuf                 2.9s\nExtracting       ━━━╸━━━━━━━━━━━━━━━━━━━       3                            0.1s[+] 3.1s\nDownloading  (5) ╸━━━━━━━━━━━━━━━━━━╸━━━  10.2MB pillow                     3.0s\nExtracting       ━━━╸━━━━━━━━━━━━━━━━━━━       3                            0.1s[+] 3.2s\nDownloading  (5) ╸━━━━━━━━━━━━━━━━━━╸━━━  10.6MB pillow                     3.1s\nExtracting       ━━━╸━━━━━━━━━━━━━━━━━━━       3                            0.1s[+] 3.3s\nDownloading  (5) ╸━━━━━━━━━━━━━━━━━━╸━━━  10.8MB pillow                     3.2s\nExtracting       ━━━╸━━━━━━━━━━━━━━━━━━━       3                            0.1s[+] 3.4s\nDownloading  (5) ╸━━━━━━━━━━━━━━━━━━╸━━━  11.1MB pillow                     3.3s\nExtracting       ━━━╸━━━━━━━━━━━━━━━━━━━       3                            0.1s[+] 3.5s\nDownloading  (5) ╸━━━━━━━━━━━━━━━━━━╸━━━  11.5MB pytorch                    3.4s\nExtracting       ━━━╸━━━━━━━━━━━━━━━━━━━       3                            0.1s[+] 3.6s\nDownloading  (5) ╸━━━━━━━━━━━━━━━━━━╸━━━  11.7MB pytorch                    3.5s\nExtracting       ━━━╸━━━━━━━━━━━━━━━━━━━       3                            0.1s[+] 3.7s\nDownloading  (5) ━╸━━━━━━━━━━━━━━━━━╸━━━  11.8MB pytorch                    3.6s\nExtracting       ━━━╸━━━━━━━━━━━━━━━━━━━       3                            0.1s[+] 3.8s\nDownloading  (5) ━╸━━━━━━━━━━━━━━━━━╸━━━  12.0MB pytorch                    3.7s\nExtracting       ━━━╸━━━━━━━━━━━━━━━━━━━       3                            0.1s[+] 3.9s\nDownloading  (5) ━╸━━━━━━━━━━━━━━━━━╸━━━  12.1MB torchaudio                 3.8s\nExtracting       ━━━╸━━━━━━━━━━━━━━━━━━━       3                            0.1sgdk-pixbuf                                         534.0kB @ 133.6kB/s  2.5s\n[+] 4.0s\nDownloading  (5) ━╸━━━━━━━━━━━━━━━━━━╸━━  12.4MB torchaudio                 3.9s\nExtracting   (1) ━━━╸━━╸━━━━━━━━━━━━━━━━       3 gdk-pixbuf                 0.1s[+] 4.1s\nDownloading  (5) ━╸━━━━━━━━━━━━━━━━━━╸━━  12.6MB torchaudio                 4.0s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 4.2s\nDownloading  (5) ━╸━━━━━━━━━━━━━━━━━━╸━━  12.8MB torchaudio                 4.1s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 4.3s\nDownloading  (5) ━╸━━━━━━━━━━━━━━━━━━╸━━  13.1MB torchvision                4.2s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 4.4s\nDownloading  (5) ━╸━━━━━━━━━━━━━━━━━━╸━━  13.4MB torchvision                4.3s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 4.5s\nDownloading  (5) ━╸━━━━━━━━━━━━━━━━━━╸━━  13.6MB torchvision                4.4s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 4.6s\nDownloading  (5) ━╸━━━━━━━━━━━━━━━━━━╸━━  13.8MB torchvision                4.5s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 4.7s\nDownloading  (5) ━╸━━━━━━━━━━━━━━━━━━╸━━  14.1MB ffmpeg                     4.6s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 4.8s\nDownloading  (5) ━╸━━━━━━━━━━━━━━━━━━╸━━  14.4MB ffmpeg                     4.7s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 4.9s\nDownloading  (5) ━╸━━━━━━━━━━━━━━━━━━╸━━  14.7MB ffmpeg                     4.8s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 5.0s\nDownloading  (5) ━╸━━━━━━━━━━━━━━━━━━╸━━  14.9MB ffmpeg                     4.9s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 5.1s\nDownloading  (5) ━╸━━━━━━━━━━━━━━━━━━╸━━  15.1MB pillow                     5.0s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 5.2s\nDownloading  (5) ━╸━━━━━━━━━━━━━━━━━━╸━━  15.3MB pillow                     5.1s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 5.3s\nDownloading  (5) ━╸━━━━━━━━━━━━━━━━━━╸━━  15.4MB pillow                     5.2s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 5.4s\nDownloading  (5) ━╸━━━━━━━━━━━━━━━━━━╸━━  15.6MB pillow                     5.3s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 5.5s\nDownloading  (5) ━╸━━━━━━━━━━━━━━━━━━╸━━  15.9MB pytorch                    5.4s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 5.6s\nDownloading  (5) ━╸━━━━━━━━━━━━━━━━━━╸━━  16.1MB pytorch                    5.5s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 5.7s\nDownloading  (5) ━╸━━━━━━━━━━━━━━━━━━╸━━  16.2MB pytorch                    5.6s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 5.8s\nDownloading  (5) ━╸━━━━━━━━━━━━━━━━━━╸━━  16.4MB pytorch                    5.7s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 5.9s\nDownloading  (5) ━╸━━━━━━━━━━━━━━━━━━╸━━  16.5MB torchaudio                 5.8s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 6.0s\nDownloading  (5) ━╸━━━━━━━━━━━━━━━━━━╸━━  16.7MB torchaudio                 5.9s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 6.1s\nDownloading  (5) ━╸━━━━━━━━━━━━━━━━━━╸━━  16.9MB torchaudio                 6.0s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 6.2s\nDownloading  (5) ━╸━━━━━━━━━━━━━━━━━━╸━━  17.1MB torchaudio                 6.1s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 6.3s\nDownloading  (5) ━╸━━━━━━━━━━━━━━━━━━╸━━  17.3MB torchvision                6.2s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 6.4s\nDownloading  (5) ━╸━━━━━━━━━━━━━━━━━━╸━━  17.5MB torchvision                6.3s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 6.5s\nDownloading  (5) ━╸━━━━━━━━━━━━━━━━━━╸━━  17.7MB torchvision                6.4s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 6.6s\nDownloading  (5) ━╸━━━━━━━━━━━━━━━━━━╸━━  17.9MB torchvision                6.5s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 6.7s\nDownloading  (5) ━━╸━━━━━━━━━━━━━━━━━╸━━  18.2MB ffmpeg                     6.6s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 6.8s\nDownloading  (5) ━━╸━━━━━━━━━━━━━━━━━╸━━  18.4MB ffmpeg                     6.7s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 6.9s\nDownloading  (5) ━━╸━━━━━━━━━━━━━━━━━╸━━  18.8MB ffmpeg                     6.8s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 7.0s\nDownloading  (5) ━━╸━━━━━━━━━━━━━━━━━╸━━  18.9MB ffmpeg                     6.9s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 7.1s\nDownloading  (5) ━━╸━━━━━━━━━━━━━━━━━╸━━  19.1MB pillow                     7.0s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 7.2s\nDownloading  (5) ━━╸━━━━━━━━━━━━━━━━━╸━━  19.3MB pillow                     7.1s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 7.3s\nDownloading  (5) ━━╸━━━━━━━━━━━━━━━━━╸━━  19.6MB pillow                     7.2s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 7.4s\nDownloading  (5) ━━╸━━━━━━━━━━━━━━━━━╸━━  19.7MB pillow                     7.3s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 7.5s\nDownloading  (5) ━━╸━━━━━━━━━━━━━━━━━╸━━  20.0MB pytorch                    7.4s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 7.6s\nDownloading  (5) ━━╸━━━━━━━━━━━━━━━━━╸━━  20.2MB pytorch                    7.5s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 7.7s\nDownloading  (5) ━━╸━━━━━━━━━━━━━━━━━╸━━  20.4MB pytorch                    7.6s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 7.8s\nDownloading  (5) ━━╸━━━━━━━━━━━━━━━━━╸━━  20.7MB pytorch                    7.7s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 7.9s\nDownloading  (5) ━━╸━━━━━━━━━━━━━━━━━╸━━  21.0MB torchaudio                 7.8s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 8.0s\nDownloading  (5) ━━╸━━━━━━━━━━━━━━━━━╸━━  21.3MB torchaudio                 7.9s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 8.1s\nDownloading  (5) ━━╸━━━━━━━━━━━━━━━━━╸━━  21.6MB torchaudio                 8.0s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 8.2s\nDownloading  (5) ━━╸━━━━━━━━━━━━━━━━━╸━━  21.7MB torchaudio                 8.1s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 8.3s\nDownloading  (5) ━━╸━━━━━━━━━━━━━━━━━╸━━  21.9MB torchvision                8.2s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 8.4s\nDownloading  (5) ━━╸━━━━━━━━━━━━━━━━━╸━━  22.2MB torchvision                8.3s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 8.5s\nDownloading  (5) ━━╸━━━━━━━━━━━━━━━━━╸━━  22.5MB torchvision                8.4s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 8.6s\nDownloading  (5) ━━╸━━━━━━━━━━━━━━━━━╸━━  22.6MB torchvision                8.5s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 8.7s\nDownloading  (5) ━━╸━━━━━━━━━━━━━━━━━╸━━  22.7MB ffmpeg                     8.6s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 8.8s\nDownloading  (5) ━━╸━━━━━━━━━━━━━━━━━╸━━  22.9MB ffmpeg                     8.7s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 8.9s\nDownloading  (5) ━━╸━━━━━━━━━━━━━━━━━╸━━  23.2MB ffmpeg                     8.8s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 9.0s\nDownloading  (5) ━━━╸━━━━━━━━━━━━━━━━╸━━  23.4MB ffmpeg                     8.9s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 9.1s\nDownloading  (5) ━━━╸━━━━━━━━━━━━━━━━╸━━  23.7MB pillow                     9.0s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 9.2s\nDownloading  (5) ━━━╸━━━━━━━━━━━━━━━━╸━━  23.9MB pillow                     9.1s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 9.3s\nDownloading  (5) ━━━╸━━━━━━━━━━━━━━━━╸━━  24.2MB pillow                     9.2s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 9.4s\nDownloading  (5) ━━━╸━━━━━━━━━━━━━━━━╸━━  24.3MB pillow                     9.3s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 9.5s\nDownloading  (5) ━━━╸━━━━━━━━━━━━━━━━╸━━  24.5MB pytorch                    9.4s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 9.6s\nDownloading  (5) ━━━╸━━━━━━━━━━━━━━━━╸━━  24.7MB pytorch                    9.5s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 9.7s\nDownloading  (5) ━━━╸━━━━━━━━━━━━━━━━╸━━  24.9MB pytorch                    9.6s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 9.8s\nDownloading  (5) ━━━╸━━━━━━━━━━━━━━━━╸━━  25.2MB pytorch                    9.7s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 9.9s\nDownloading  (5) ━━━╸━━━━━━━━━━━━━━━━╸━━  25.4MB torchaudio                 9.8s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 10.0s\nDownloading  (5) ━━━╸━━━━━━━━━━━━━━━━╸━━  25.7MB torchaudio                 9.9s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 10.1s\nDownloading  (5) ━━━╸━━━━━━━━━━━━━━━━╸━━  25.9MB torchaudio                10.0s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 10.2s\nDownloading  (5) ━━━╸━━━━━━━━━━━━━━━━╸━━  26.1MB torchaudio                10.1s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 10.3s\nDownloading  (5) ━━━╸━━━━━━━━━━━━━━━━╸━━  26.2MB torchvision               10.2s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 10.4s\nDownloading  (5) ━━━╸━━━━━━━━━━━━━━━━╸━━  26.5MB torchvision               10.3s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 10.5s\nDownloading  (5) ━━━╸━━━━━━━━━━━━━━━━╸━━  26.8MB torchvision               10.4s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 10.6s\nDownloading  (5) ━━━╸━━━━━━━━━━━━━━━━╸━━  27.1MB torchvision               10.5s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 10.7s\nDownloading  (5) ━━━╸━━━━━━━━━━━━━━━━╸━━  27.3MB ffmpeg                    10.6s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 10.8s\nDownloading  (5) ━━━╸━━━━━━━━━━━━━━━━╸━━  27.5MB ffmpeg                    10.7s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 10.9s\nDownloading  (5) ━━━╸━━━━━━━━━━━━━━━━╸━━  27.8MB ffmpeg                    10.8s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 11.0s\nDownloading  (5) ━━━╸━━━━━━━━━━━━━━━━╸━━  28.0MB ffmpeg                    10.9s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 11.1s\nDownloading  (5) ━━━╸━━━━━━━━━━━━━━━━╸━━  28.3MB pillow                    11.0s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 11.2s\nDownloading  (5) ━━━━╸━━━━━━━━━━━━━━━╸━━  28.6MB pillow                    11.1s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 11.3s\nDownloading  (5) ━━━━╸━━━━━━━━━━━━━━━╸━━  29.0MB pillow                    11.2s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 11.4s\nDownloading  (5) ━━━━╸━━━━━━━━━━━━━━━╸━━  29.0MB pillow                    11.3s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 11.5s\nDownloading  (5) ━━━━╸━━━━━━━━━━━━━━━╸━━  29.3MB pytorch                   11.4s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 11.6s\nDownloading  (5) ━━━━╸━━━━━━━━━━━━━━━╸━━  29.4MB pytorch                   11.5s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 11.7s\nDownloading  (5) ━━━━╸━━━━━━━━━━━━━━━╸━━  29.5MB pytorch                   11.6s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 11.8s\nDownloading  (5) ━━━━╸━━━━━━━━━━━━━━━╸━━  29.7MB pytorch                   11.7s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 11.9s\nDownloading  (5) ━━━━╸━━━━━━━━━━━━━━━╸━━  30.0MB torchaudio                11.8s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 12.0s\nDownloading  (5) ━━━━╸━━━━━━━━━━━━━━━╸━━  30.3MB torchaudio                11.9s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 12.1s\nDownloading  (5) ━━━━╸━━━━━━━━━━━━━━━╸━━  30.5MB torchaudio                12.0s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 12.2s\nDownloading  (5) ━━━━╸━━━━━━━━━━━━━━━╸━━  30.8MB torchaudio                12.1s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 12.3s\nDownloading  (5) ━━━━╸━━━━━━━━━━━━━━━╸━━  31.0MB torchvision               12.2s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 12.4s\nDownloading  (5) ━━━━╸━━━━━━━━━━━━━━━╸━━  31.1MB torchvision               12.3s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 12.5s\nDownloading  (5) ━━━━╸━━━━━━━━━━━━━━━╸━━  31.3MB torchvision               12.4s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 12.6s\nDownloading  (5) ━━━━╸━━━━━━━━━━━━━━━╸━━  31.6MB torchvision               12.5s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 12.7s\nDownloading  (5) ━━━━╸━━━━━━━━━━━━━━━╸━━  31.9MB ffmpeg                    12.6s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 12.8s\nDownloading  (5) ━━━━╸━━━━━━━━━━━━━━━╸━━  32.1MB ffmpeg                    12.7s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 12.9s\nDownloading  (5) ━━━━╸━━━━━━━━━━━━━━━╸━━  32.5MB ffmpeg                    12.8s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 13.0s\nDownloading  (5) ━━━━╸━━━━━━━━━━━━━━━╸━━  32.7MB ffmpeg                    12.9s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 13.1s\nDownloading  (5) ━━━━╸━━━━━━━━━━━━━━━╸━━  32.9MB pillow                    13.0s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 13.2s\nDownloading  (5) ━━━━╸━━━━━━━━━━━━━━━╸━━  33.3MB pillow                    13.1s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 13.3s\nDownloading  (5) ━━━━╸━━━━━━━━━━━━━━━╸━━  33.5MB pillow                    13.2s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 13.4s\nDownloading  (5) ━━━━╸━━━━━━━━━━━━━━━╸━━  33.7MB pillow                    13.3s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 13.5s\nDownloading  (5) ━━━━╸━━━━━━━━━━━━━━━╸━━  33.9MB pytorch                   13.4s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 13.6s\nDownloading  (5) ━━━━╸━━━━━━━━━━━━━━━╸━━  34.1MB pytorch                   13.5s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 13.7s\nDownloading  (5) ━━━━╸━━━━━━━━━━━━━━━╸━━  34.4MB pytorch                   13.6s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 13.8s\nDownloading  (5) ━━━━╸━━━━━━━━━━━━━━━╸━━  34.6MB pytorch                   13.7s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 13.9s\nDownloading  (5) ━━━━╸━━━━━━━━━━━━━━━╸━━  35.0MB torchaudio                13.8s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 14.0s\nDownloading  (5) ━━━━━╸━━━━━━━━━━━━━━╸━━  35.3MB torchaudio                13.9s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 14.1s\nDownloading  (5) ━━━━━╸━━━━━━━━━━━━━━╸━━  35.4MB torchaudio                14.0s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 14.2s\nDownloading  (5) ━━━━━╸━━━━━━━━━━━━━━╸━━  35.6MB torchaudio                14.1s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 14.3s\nDownloading  (5) ━━━━━╸━━━━━━━━━━━━━━╸━━  35.9MB torchvision               14.2s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 14.4s\nDownloading  (5) ━━━━━╸━━━━━━━━━━━━━━╸━━  36.1MB torchvision               14.3s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 14.5s\nDownloading  (5) ━━━━━╸━━━━━━━━━━━━━━╸━━  36.3MB torchvision               14.4s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 14.6s\nDownloading  (5) ━━━━━╸━━━━━━━━━━━━━━╸━━  36.6MB torchvision               14.5s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 14.7s\nDownloading  (5) ━━━━━╸━━━━━━━━━━━━━━╸━━  36.8MB ffmpeg                    14.6s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 14.8s\nDownloading  (5) ━━━━━╸━━━━━━━━━━━━━━╸━━  37.1MB ffmpeg                    14.7s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 14.9s\nDownloading  (5) ━━━━━╸━━━━━━━━━━━━━━╸━━  37.4MB ffmpeg                    14.8s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 15.0s\nDownloading  (5) ━━━━━╸━━━━━━━━━━━━━━╸━━  37.6MB ffmpeg                    14.9s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 15.1s\nDownloading  (5) ━━━━━╸━━━━━━━━━━━━━━╸━━  37.9MB pillow                    15.0s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 15.2s\nDownloading  (5) ━━━━━╸━━━━━━━━━━━━━━╸━━  38.1MB pillow                    15.1s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 15.3s\nDownloading  (5) ━━━━━╸━━━━━━━━━━━━━━╸━━  38.4MB pillow                    15.2s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 15.4s\nDownloading  (5) ━━━━━╸━━━━━━━━━━━━━━╸━━  38.7MB pillow                    15.3s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 15.5s\nDownloading  (5) ━━━━━╸━━━━━━━━━━━━━━╸━━  38.8MB pytorch                   15.4s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 15.6s\nDownloading  (5) ━━━━━╸━━━━━━━━━━━━━━╸━━  39.1MB pytorch                   15.5s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 15.7s\nDownloading  (5) ━━━━━╸━━━━━━━━━━━━━━╸━━  39.3MB pytorch                   15.6s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 15.8s\nDownloading  (5) ━━━━━╸━━━━━━━━━━━━━━╸━━  39.5MB pytorch                   15.7s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 15.9s\nDownloading  (5) ━━━━━╸━━━━━━━━━━━━━━╸━━  39.7MB torchaudio                15.8s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 16.0s\nDownloading  (5) ━━━━━╸━━━━━━━━━━━━━━╸━━  40.0MB torchaudio                15.9s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 16.1s\nDownloading  (5) ━━━━━╸━━━━━━━━━━━━━━╸━━  40.1MB torchaudio                16.0s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 16.2s\nDownloading  (5) ━━━━━━╸━━━━━━━━━━━━━╸━━  40.5MB torchaudio                16.1s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 16.3s\nDownloading  (5) ━━━━━━╸━━━━━━━━━━━━━╸━━  40.8MB torchvision               16.2s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 16.4s\nDownloading  (5) ━━━━━━╸━━━━━━━━━━━━━╸━━  41.0MB torchvision               16.3s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 16.5s\nDownloading  (5) ━━━━━━╸━━━━━━━━━━━━━╸━━  41.3MB torchvision               16.4s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 16.6s\nDownloading  (5) ━━━━━━╸━━━━━━━━━━━━━╸━━  41.6MB torchvision               16.5s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 16.7s\nDownloading  (5) ━━━━━━╸━━━━━━━━━━━━━╸━━  41.8MB ffmpeg                    16.6s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 16.8s\nDownloading  (5) ━━━━━━╸━━━━━━━━━━━━━╸━━  42.0MB ffmpeg                    16.7s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 16.9s\nDownloading  (5) ━━━━━━╸━━━━━━━━━━━━━╸━━  42.3MB ffmpeg                    16.8s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 17.0s\nDownloading  (5) ━━━━━━╸━━━━━━━━━━━━━╸━━  42.7MB ffmpeg                    16.9s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 17.1s\nDownloading  (5) ━━━━━━╸━━━━━━━━━━━━━╸━━  42.9MB pillow                    17.0s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 17.2s\nDownloading  (5) ━━━━━━╸━━━━━━━━━━━━━╸━━  43.1MB pillow                    17.1s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 17.3s\nDownloading  (5) ━━━━━━╸━━━━━━━━━━━━━╸━━  43.3MB pillow                    17.2s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 17.4s\nDownloading  (5) ━━━━━━╸━━━━━━━━━━━━━╸━━  43.5MB pillow                    17.3s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2s[+] 17.5s\nDownloading  (5) ━━━━━━╸━━━━━━━━━━━━━╸━━  43.9MB pytorch                   17.4s\nExtracting       ━━━━━╸━━━━━━━━━━━━━━━━━       4                            0.2storchaudio                                           6.1MB @ 346.5kB/s 17.6s\n[+] 17.6s\nDownloading  (5) ━━━━━━╸━━━━━━━━━━━━━╸━━  44.1MB pytorch                   17.5s\nExtracting   (1) ━━━━━╸━━╸━━━━━━━━━━━━━━       4 torchaudio                 0.2s[+] 17.7s\nDownloading  (5) ━━━━━━╸━━━━━━━━━━━━━╸━━  44.3MB pytorch                   17.6s\nExtracting   (1) ━━━━━╸━━╸━━━━━━━━━━━━━━       4 torchaudio                 0.3s[+] 17.8s\nDownloading  (5) ━━━━━━╸━━━━━━━━━━━━━╸━━  44.5MB pytorch                   17.7s\nExtracting   (1) ━━━━━╸━━╸━━━━━━━━━━━━━━       4 torchaudio                 0.4s[+] 17.9s\nDownloading  (5) ━━━━━━╸━━━━━━━━━━━━━╸━━  44.7MB torchvision               17.8s\nExtracting   (1) ━━━━━╸━━╸━━━━━━━━━━━━━━       4 torchaudio                 0.5s[+] 18.0s\nDownloading  (5) ━━━━━━╸━━━━━━━━━━━━━╸━━  45.0MB torchvision               17.9s\nExtracting   (1) ━━━━━╸━━╸━━━━━━━━━━━━━━       4 torchaudio                 0.6s[+] 18.1s\nDownloading  (5) ━━━━━━╸━━━━━━━━━━━━━╸━━  45.2MB torchvision               18.0s\nExtracting       ━━━━━━━╸━━━━━━━━━━━━━━━       5                            0.7s[+] 18.2s\nDownloading  (5) ━━━━━━━╸━━━━━━━━━━━━╸━━  45.6MB torchvision               18.1s\nExtracting       ━━━━━━━╸━━━━━━━━━━━━━━━       5                            0.7slibwebp                                             78.2kB @   4.3kB/s  0.7s\n[+] 18.3s\nDownloading  (5) ━━━━━━━╸━━━━━━━━━━━━━╸━  45.9MB ffmpeg                    18.2s\nExtracting       ━━━━━━━━╸━━━━━━━━━━━━━━       6                            0.7storchvision                                          7.2MB @ 393.9kB/s 17.7s\n[+] 18.4s\nDownloading  (5) ━━━━━━━╸━━━━━━━━━━━━━╸━  46.1MB ffmpeg                    18.3s\nExtracting   (1) ━━━━━━━━╸━━╸━━━━━━━━━━━       6 torchvision                0.7s[+] 18.5s\nDownloading  (5) ━━━━━━━╸━━━━━━━━━━━━━╸━  46.4MB ffmpeg                    18.4s\nExtracting   (1) ━━━━━━━━╸━━╸━━━━━━━━━━━       6 torchvision                0.8s[+] 18.6s\nDownloading  (5) ━━━━━━━╸━━━━━━━━━━━━━╸━  46.6MB ffmpeg                    18.5s\nExtracting   (1) ━━━━━━━━╸━━╸━━━━━━━━━━━       6 torchvision                0.9s[+] 18.7s\nDownloading  (5) ━━━━━━━╸━━━━━━━━━━━━━╸━  46.7MB graphviz                  18.6s\nExtracting   (1) ━━━━━━━━╸━━╸━━━━━━━━━━━       6 torchvision                1.0s[+] 18.8s\nDownloading  (5) ━━━━━━━╸━━━━━━━━━━━━━╸━  47.0MB graphviz                  18.7s\nExtracting   (1) ━━━━━━━━╸━━╸━━━━━━━━━━━       6 torchvision                1.1s[+] 18.9s\nDownloading  (5) ━━━━━━━╸━━━━━━━━━━━━━╸━  47.3MB graphviz                  18.8s\nExtracting       ━━━━━━━━━━╸━━━━━━━━━━━━       7                            1.2s[+] 19.0s\nDownloading  (5) ━━━━━━━╸━━━━━━━━━━━━━╸━  47.6MB graphviz                  18.9s\nExtracting       ━━━━━━━━━━╸━━━━━━━━━━━━       7                            1.2s[+] 19.1s\nDownloading  (5) ━━━━━━━╸━━━━━━━━━━━━━╸━  47.9MB libtiff                   19.0s\nExtracting       ━━━━━━━━━━╸━━━━━━━━━━━━       7                            1.2s[+] 19.2s\nDownloading  (5) ━━━━━━━╸━━━━━━━━━━━━━╸━  48.2MB libtiff                   19.1s\nExtracting       ━━━━━━━━━━╸━━━━━━━━━━━━       7                            1.2s[+] 19.3s\nDownloading  (5) ━━━━━━━╸━━━━━━━━━━━━━╸━  48.4MB libtiff                   19.2s\nExtracting       ━━━━━━━━━━╸━━━━━━━━━━━━       7                            1.2s[+] 19.4s\nDownloading  (5) ━━━━━━━╸━━━━━━━━━━━━━╸━  48.6MB libtiff                   19.3s\nExtracting       ━━━━━━━━━━╸━━━━━━━━━━━━       7                            1.2s[+] 19.5s\nDownloading  (5) ━━━━━━━╸━━━━━━━━━━━━━╸━  48.9MB pillow                    19.4s\nExtracting       ━━━━━━━━━━╸━━━━━━━━━━━━       7                            1.2s[+] 19.6s\nDownloading  (5) ━━━━━━━╸━━━━━━━━━━━━━╸━  49.2MB pillow                    19.5s\nExtracting       ━━━━━━━━━━╸━━━━━━━━━━━━       7                            1.2slibtiff                                            347.5kB @  17.7kB/s  1.2s\n[+] 19.7s\nDownloading  (5) ━━━━━━━╸━━━━━━━━━━━━━╸━  49.4MB pillow                    19.6s\nExtracting       ━━━━━━━━━━━━╸━━━━━━━━━━       8                            1.2s[+] 19.8s\nDownloading  (5) ━━━━━━━╸━━━━━━━━━━━━━╸━  49.7MB pillow                    19.7s\nExtracting       ━━━━━━━━━━━━╸━━━━━━━━━━       8                            1.2s[+] 19.9s\nDownloading  (5) ━━━━━━━╸━━━━━━━━━━━━━╸━  49.9MB pytorch                   19.8s\nExtracting       ━━━━━━━━━━━━╸━━━━━━━━━━       8                            1.2s[+] 20.0s\nDownloading  (5) ━━━━━━━╸━━━━━━━━━━━━━╸━  50.2MB pytorch                   19.9s\nExtracting       ━━━━━━━━━━━━╸━━━━━━━━━━       8                            1.2s[+] 20.1s\nDownloading  (5) ━━━━━━━╸━━━━━━━━━━━━━╸━  50.4MB pytorch                   20.0s\nExtracting       ━━━━━━━━━━━━╸━━━━━━━━━━       8                            1.2s[+] 20.2s\nDownloading  (5) ━━━━━━━╸━━━━━━━━━━━━━╸━  50.7MB pytorch                   20.1s\nExtracting       ━━━━━━━━━━━━╸━━━━━━━━━━       8                            1.2s[+] 20.3s\nDownloading  (5) ━━━━━━━╸━━━━━━━━━━━━━╸━  51.0MB ffmpeg                    20.2s\nExtracting       ━━━━━━━━━━━━╸━━━━━━━━━━       8                            1.2s[+] 20.4s\nDownloading  (5) ━━━━━━━╸━━━━━━━━━━━━━╸━  51.3MB ffmpeg                    20.3s\nExtracting       ━━━━━━━━━━━━╸━━━━━━━━━━       8                            1.2s[+] 20.5s\nDownloading  (5) ━━━━━━━╸━━━━━━━━━━━━━╸━  51.7MB ffmpeg                    20.4s\nExtracting       ━━━━━━━━━━━━╸━━━━━━━━━━       8                            1.2slcms2                                              205.8kB @  10.0kB/s  0.9s\n[+] 20.6s\nDownloading  (5) ━━━━━━━━╸━━━━━━━━━━━━━━  52.1MB ffmpeg                    20.5s\nExtracting       ━━━━━━━━━━━━━╸━━━━━━━━━       9                            1.2s[+] 20.7s\nDownloading  (5) ━━━━━━━━╸━━━━━━━━━━━━━━  52.4MB graphviz                  20.6s\nExtracting       ━━━━━━━━━━━━━╸━━━━━━━━━       9                            1.2s[+] 20.8s\nDownloading  (5) ━━━━━━━━╸━━━━━━━━━━━━━━  52.5MB graphviz                  20.7s\nExtracting       ━━━━━━━━━━━━━╸━━━━━━━━━       9                            1.2s[+] 20.9s\nDownloading  (5) ━━━━━━━━╸━━━━━━━━━━━━━━  52.9MB graphviz                  20.8s\nExtracting       ━━━━━━━━━━━━━╸━━━━━━━━━       9                            1.2s[+] 21.0s\nDownloading  (5) ━━━━━━━━╸━━━━━━━━━━━━━━  53.2MB graphviz                  20.9s\nExtracting       ━━━━━━━━━━━━━╸━━━━━━━━━       9                            1.2s[+] 21.1s\nDownloading  (5) ━━━━━━━━╸━━━━━━━━━━━━━━  53.5MB libgd                     21.0s\nExtracting       ━━━━━━━━━━━━━╸━━━━━━━━━       9                            1.2s[+] 21.2s\nDownloading  (5) ━━━━━━━━╸━━━━━━━━━━━━━━  53.8MB libgd                     21.1s\nExtracting       ━━━━━━━━━━━━━╸━━━━━━━━━       9                            1.2s[+] 21.3s\nDownloading  (5) ━━━━━━━━╸━━━━━━━━━━━━━━  54.2MB libgd                     21.2s\nExtracting       ━━━━━━━━━━━━━╸━━━━━━━━━       9                            1.2s[+] 21.4s\nDownloading  (5) ━━━━━━━━╸━━━━━━━━━━━━━━  54.4MB libgd                     21.3s\nExtracting       ━━━━━━━━━━━━━╸━━━━━━━━━       9                            1.2s[+] 21.5s\nDownloading  (5) ━━━━━━━━╸━━━━━━━━━━━━━━  54.7MB pillow                    21.4s\nExtracting       ━━━━━━━━━━━━━╸━━━━━━━━━       9                            1.2s[+] 21.6s\nDownloading  (5) ━━━━━━━━╸━━━━━━━━━━━━━━  54.9MB pillow                    21.5s\nExtracting       ━━━━━━━━━━━━━╸━━━━━━━━━       9                            1.2s[+] 21.7s\nDownloading  (5) ━━━━━━━━╸━━━━━━━━━━━━━━  55.1MB pillow                    21.6s\nExtracting       ━━━━━━━━━━━━━╸━━━━━━━━━       9                            1.2slibgd                                              198.9kB @   9.2kB/s  1.2s\n[+] 21.8s\nDownloading  (4) ━━━━━━━━╸━━━━━━━━━━━━━━  55.4MB pillow                    21.7s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 21.9s\nDownloading  (4) ━━━━━━━━╸━━━━━━━━━━━━━━  55.5MB pytorch                   21.8s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 22.0s\nDownloading  (4) ━━━━━━━━╸━━━━━━━━━━━━━━  55.8MB pytorch                   21.9s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 22.1s\nDownloading  (4) ━━━━━━━━╸━━━━━━━━━━━━━━  56.1MB pytorch                   22.0s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 22.2s\nDownloading  (4) ━━━━━━━━╸━━━━━━━━━━━━━━  56.3MB pytorch                   22.1s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 22.3s\nDownloading  (4) ━━━━━━━━╸━━━━━━━━━━━━━━  56.6MB ffmpeg                    22.2s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 22.4s\nDownloading  (4) ━━━━━━━━╸━━━━━━━━━━━━━━  56.9MB ffmpeg                    22.3s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 22.5s\nDownloading  (4) ━━━━━━━━━╸━━━━━━━━━━━━━  57.2MB ffmpeg                    22.4s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 22.6s\nDownloading  (4) ━━━━━━━━━╸━━━━━━━━━━━━━  57.4MB ffmpeg                    22.5s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 22.7s\nDownloading  (4) ━━━━━━━━━╸━━━━━━━━━━━━━  57.7MB graphviz                  22.6s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 22.8s\nDownloading  (4) ━━━━━━━━━╸━━━━━━━━━━━━━  57.9MB graphviz                  22.7s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 22.9s\nDownloading  (4) ━━━━━━━━━╸━━━━━━━━━━━━━  58.1MB graphviz                  22.8s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 23.0s\nDownloading  (4) ━━━━━━━━━╸━━━━━━━━━━━━━  58.5MB graphviz                  22.9s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 23.1s\nDownloading  (4) ━━━━━━━━━╸━━━━━━━━━━━━━  58.8MB pillow                    23.0s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 23.2s\nDownloading  (4) ━━━━━━━━━╸━━━━━━━━━━━━━  58.9MB pillow                    23.1s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 23.3s\nDownloading  (4) ━━━━━━━━━╸━━━━━━━━━━━━━  59.3MB pillow                    23.2s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 23.4s\nDownloading  (4) ━━━━━━━━━╸━━━━━━━━━━━━━  59.6MB pillow                    23.3s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 23.5s\nDownloading  (4) ━━━━━━━━━╸━━━━━━━━━━━━━  59.7MB pytorch                   23.4s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 23.6s\nDownloading  (4) ━━━━━━━━━╸━━━━━━━━━━━━━  60.0MB pytorch                   23.5s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 23.7s\nDownloading  (4) ━━━━━━━━━╸━━━━━━━━━━━━━  60.4MB pytorch                   23.6s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 23.8s\nDownloading  (4) ━━━━━━━━━╸━━━━━━━━━━━━━  60.6MB pytorch                   23.7s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 23.9s\nDownloading  (4) ━━━━━━━━━╸━━━━━━━━━━━━━  60.9MB ffmpeg                    23.8s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 24.0s\nDownloading  (4) ━━━━━━━━━╸━━━━━━━━━━━━━  61.1MB ffmpeg                    23.9s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 24.1s\nDownloading  (4) ━━━━━━━━━╸━━━━━━━━━━━━━  61.4MB ffmpeg                    24.0s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 24.2s\nDownloading  (4) ━━━━━━━━━╸━━━━━━━━━━━━━  61.5MB ffmpeg                    24.1s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 24.3s\nDownloading  (4) ━━━━━━━━━╸━━━━━━━━━━━━━  61.8MB graphviz                  24.2s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 24.4s\nDownloading  (4) ━━━━━━━━━╸━━━━━━━━━━━━━  62.0MB graphviz                  24.3s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 24.5s\nDownloading  (4) ━━━━━━━━━╸━━━━━━━━━━━━━  62.2MB graphviz                  24.4s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 24.6s\nDownloading  (4) ━━━━━━━━━━╸━━━━━━━━━━━━  62.5MB graphviz                  24.5s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 24.7s\nDownloading  (4) ━━━━━━━━━━╸━━━━━━━━━━━━  62.6MB pillow                    24.6s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 24.8s\nDownloading  (4) ━━━━━━━━━━╸━━━━━━━━━━━━  62.8MB pillow                    24.7s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 24.9s\nDownloading  (4) ━━━━━━━━━━╸━━━━━━━━━━━━  63.0MB pillow                    24.8s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2s[+] 25.0s\nDownloading  (4) ━━━━━━━━━━╸━━━━━━━━━━━━  63.4MB pillow                    24.9s\nExtracting       ━━━━━━━━━━━━━━━╸━━━━━━━      10                            1.2sgraphviz                                             4.6MB @ 184.5kB/s  6.8s\n[+] 25.1s\nDownloading  (3) ━━━━━━━━━━╸━━━━━━━━━━━━  63.7MB pytorch                   25.0s\nExtracting   (1) ━━━━━━━━━━━━━━━╸━━╸━━━━      10 graphviz                   1.2s[+] 25.2s\nDownloading  (3) ━━━━━━━━━━╸━━━━━━━━━━━━  64.0MB pytorch                   25.1s\nExtracting       ━━━━━━━━━━━━━━━━╸━━━━━━      11                            1.3s[+] 25.3s\nDownloading  (3) ━━━━━━━━━━╸━━━━━━━━━━━━  64.5MB pytorch                   25.2s\nExtracting       ━━━━━━━━━━━━━━━━╸━━━━━━      11                            1.3s[+] 25.4s\nDownloading  (3) ━━━━━━━━━━╸━━━━━━━━━━━━  64.7MB pytorch                   25.3s\nExtracting       ━━━━━━━━━━━━━━━━╸━━━━━━      11                            1.3s[+] 25.5s\nDownloading  (3) ━━━━━━━━━━╸━━━━━━━━━━━━  65.1MB ffmpeg                    25.4s\nExtracting       ━━━━━━━━━━━━━━━━╸━━━━━━      11                            1.3s[+] 25.6s\nDownloading  (3) ━━━━━━━━━━╸━━━━━━━━━━━━  65.2MB ffmpeg                    25.5s\nExtracting       ━━━━━━━━━━━━━━━━╸━━━━━━      11                            1.3s[+] 25.7s\nDownloading  (3) ━━━━━━━━━━╸━━━━━━━━━━━━  65.5MB ffmpeg                    25.6s\nExtracting       ━━━━━━━━━━━━━━━━╸━━━━━━      11                            1.3s[+] 25.8s\nDownloading  (3) ━━━━━━━━━━╸━━━━━━━━━━━━  65.7MB ffmpeg                    25.7s\nExtracting       ━━━━━━━━━━━━━━━━╸━━━━━━      11                            1.3s[+] 25.9s\nDownloading  (3) ━━━━━━━━━━╸━━━━━━━━━━━━  66.0MB pillow                    25.8s\nExtracting       ━━━━━━━━━━━━━━━━╸━━━━━━      11                            1.3s[+] 26.0s\nDownloading  (3) ━━━━━━━━━━╸━━━━━━━━━━━━  66.1MB pillow                    25.9s\nExtracting       ━━━━━━━━━━━━━━━━╸━━━━━━      11                            1.3s[+] 26.1s\nDownloading  (3) ━━━━━━━━━━╸━━━━━━━━━━━━  66.5MB pillow                    26.0s\nExtracting       ━━━━━━━━━━━━━━━━╸━━━━━━      11                            1.3s[+] 26.2s\nDownloading  (3) ━━━━━━━━━━╸━━━━━━━━━━━━  66.8MB pillow                    26.1s\nExtracting       ━━━━━━━━━━━━━━━━╸━━━━━━      11                            1.3s[+] 26.3s\nDownloading  (3) ━━━━━━━━━━╸━━━━━━━━━━━━  66.9MB pytorch                   26.2s\nExtracting       ━━━━━━━━━━━━━━━━╸━━━━━━      11                            1.3s[+] 26.4s\nDownloading  (3) ━━━━━━━━━━╸━━━━━━━━━━━━  67.4MB pytorch                   26.3s\nExtracting       ━━━━━━━━━━━━━━━━╸━━━━━━      11                            1.3s[+] 26.5s\nDownloading  (3) ━━━━━━━━━━╸━━━━━━━━━━━━  67.8MB pytorch                   26.4s\nExtracting       ━━━━━━━━━━━━━━━━╸━━━━━━      11                            1.3s[+] 26.6s\nDownloading  (3) ━━━━━━━━━━╸━━━━━━━━━━━━  68.1MB pytorch                   26.5s\nExtracting       ━━━━━━━━━━━━━━━━╸━━━━━━      11                            1.3sffmpeg                                               8.4MB @ 317.0kB/s 22.6s\n[+] 26.7s\nDownloading  (2) ━━━━━━━━━━╸━━━━━━━━━━━━  68.5MB pillow                    26.6s\nExtracting   (1) ━━━━━━━━━━━━━━━━━╸━╸━━━      11 ffmpeg                     1.3s[+] 26.8s\nDownloading  (2) ━━━━━━━━━━╸━━━━━━━━━━━━  68.7MB pillow                    26.7s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 26.9s\nDownloading  (2) ━━━━━━━━━━━╸━━━━━━━━━━━  68.8MB pillow                    26.8s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 27.0s\nDownloading  (2) ━━━━━━━━━━━╸━━━━━━━━━━━  69.2MB pillow                    26.9s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 27.1s\nDownloading  (2) ━━━━━━━━━━━╸━━━━━━━━━━━  69.5MB pytorch                   27.0s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 27.2s\nDownloading  (2) ━━━━━━━━━━━╸━━━━━━━━━━━  69.8MB pytorch                   27.1s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 27.3s\nDownloading  (2) ━━━━━━━━━━━╸━━━━━━━━━━━  70.2MB pytorch                   27.2s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 27.4s\nDownloading  (2) ━━━━━━━━━━━╸━━━━━━━━━━━  70.4MB pytorch                   27.3s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 27.5s\nDownloading  (2) ━━━━━━━━━━━╸━━━━━━━━━━━  70.6MB pillow                    27.4s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 27.6s\nDownloading  (2) ━━━━━━━━━━━╸━━━━━━━━━━━  70.8MB pillow                    27.5s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 27.7s\nDownloading  (2) ━━━━━━━━━━━╸━━━━━━━━━━━  71.3MB pillow                    27.6s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 27.8s\nDownloading  (2) ━━━━━━━━━━━╸━━━━━━━━━━━  71.6MB pillow                    27.7s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 27.9s\nDownloading  (2) ━━━━━━━━━━━╸━━━━━━━━━━━  71.8MB pytorch                   27.8s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 28.0s\nDownloading  (2) ━━━━━━━━━━━╸━━━━━━━━━━━  72.1MB pytorch                   27.9s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 28.1s\nDownloading  (2) ━━━━━━━━━━━╸━━━━━━━━━━━  72.2MB pytorch                   28.0s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 28.2s\nDownloading  (2) ━━━━━━━━━━━╸━━━━━━━━━━━  72.5MB pytorch                   28.1s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 28.3s\nDownloading  (2) ━━━━━━━━━━━╸━━━━━━━━━━━  72.8MB pillow                    28.2s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 28.4s\nDownloading  (2) ━━━━━━━━━━━╸━━━━━━━━━━━  73.1MB pillow                    28.3s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 28.5s\nDownloading  (2) ━━━━━━━━━━━╸━━━━━━━━━━━  73.3MB pillow                    28.4s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 28.6s\nDownloading  (2) ━━━━━━━━━━━╸━━━━━━━━━━━  73.6MB pillow                    28.5s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 28.7s\nDownloading  (2) ━━━━━━━━━━━╸━━━━━━━━━━━  73.7MB pytorch                   28.6s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 28.8s\nDownloading  (2) ━━━━━━━━━━━╸━━━━━━━━━━━  73.8MB pytorch                   28.7s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 28.9s\nDownloading  (2) ━━━━━━━━━━━╸━━━━━━━━━━━  73.8MB pytorch                   28.8s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 29.0s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  74.0MB pytorch                   28.9s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 29.1s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  74.0MB pillow                    29.0s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 29.2s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  74.2MB pillow                    29.1s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 29.3s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  74.3MB pillow                    29.2s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 29.4s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  74.5MB pillow                    29.3s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 29.5s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  74.7MB pytorch                   29.4s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 29.6s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  74.8MB pytorch                   29.5s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 29.7s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  74.9MB pytorch                   29.6s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 29.8s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  75.0MB pytorch                   29.7s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 29.9s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  75.2MB pillow                    29.8s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 30.0s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  75.3MB pillow                    29.9s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 30.1s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  75.5MB pillow                    30.0s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 30.2s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  75.6MB pillow                    30.1s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 30.3s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  75.9MB pytorch                   30.2s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 30.4s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  76.1MB pytorch                   30.3s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 30.5s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  76.1MB pytorch                   30.4s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 30.6s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  76.2MB pytorch                   30.5s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 30.7s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  76.3MB pillow                    30.6s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 30.8s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  76.4MB pillow                    30.7s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 30.9s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  76.5MB pillow                    30.8s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 31.0s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  76.7MB pillow                    30.9s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 31.1s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  76.9MB pytorch                   31.0s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 31.2s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  77.0MB pytorch                   31.1s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 31.3s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  77.2MB pytorch                   31.2s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 31.4s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  77.4MB pytorch                   31.3s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 31.5s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  77.5MB pillow                    31.4s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 31.6s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  77.6MB pillow                    31.5s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 31.7s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  77.7MB pillow                    31.6s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 31.8s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  77.9MB pillow                    31.7s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 31.9s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  78.0MB pytorch                   31.8s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 32.0s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  78.2MB pytorch                   31.9s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 32.1s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  78.3MB pytorch                   32.0s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 32.2s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  78.4MB pytorch                   32.1s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 32.3s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  78.6MB pillow                    32.2s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 32.4s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  78.7MB pillow                    32.3s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 32.5s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  78.8MB pillow                    32.4s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 32.6s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  78.9MB pillow                    32.5s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 32.7s\nDownloading  (2) ━━━━━━━━━━━━╸━━━━━━━━━━  79.1MB pytorch                   32.6s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 32.8s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  79.2MB pytorch                   32.7s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 32.9s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  79.3MB pytorch                   32.8s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 33.0s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  79.4MB pytorch                   32.9s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 33.1s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  79.5MB pillow                    33.0s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 33.2s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  79.8MB pillow                    33.1s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 33.3s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  79.9MB pillow                    33.2s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 33.4s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  80.1MB pillow                    33.3s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 33.5s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  80.3MB pytorch                   33.4s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 33.6s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  80.5MB pytorch                   33.5s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 33.7s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  80.5MB pytorch                   33.6s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 33.8s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  80.7MB pytorch                   33.7s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 33.9s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  80.8MB pillow                    33.8s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 34.0s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  80.8MB pillow                    33.9s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 34.1s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  81.0MB pillow                    34.0s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 34.2s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  81.1MB pillow                    34.1s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 34.3s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  81.1MB pytorch                   34.2s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 34.4s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  81.3MB pytorch                   34.3s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 34.5s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  81.5MB pytorch                   34.4s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 34.6s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  81.7MB pytorch                   34.5s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 34.7s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  81.9MB pillow                    34.6s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 34.8s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  82.1MB pillow                    34.7s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 34.9s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  82.2MB pillow                    34.8s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 35.0s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  82.2MB pillow                    34.9s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 35.1s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  82.3MB pytorch                   35.0s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 35.2s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  82.4MB pytorch                   35.1s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 35.3s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  82.5MB pytorch                   35.2s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 35.4s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  82.7MB pytorch                   35.3s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 35.5s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  82.8MB pillow                    35.4s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 35.6s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  83.0MB pillow                    35.5s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 35.7s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  83.2MB pillow                    35.6s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 35.8s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  83.3MB pillow                    35.7s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 35.9s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  83.6MB pytorch                   35.8s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 36.0s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  83.6MB pytorch                   35.9s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 36.1s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  83.9MB pytorch                   36.0s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 36.2s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  83.9MB pytorch                   36.1s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 36.3s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  84.0MB pillow                    36.2s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 36.4s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  84.2MB pillow                    36.3s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 36.5s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  84.4MB pillow                    36.4s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 36.6s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  84.6MB pillow                    36.5s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 36.7s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  84.8MB pytorch                   36.6s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 36.8s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  85.0MB pytorch                   36.7s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 36.9s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  85.2MB pytorch                   36.8s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 37.0s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  85.3MB pytorch                   36.9s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 37.1s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  85.4MB pillow                    37.0s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 37.2s\nDownloading  (2) ━━━━━━━━━━━━━╸━━━━━━━━━  85.6MB pillow                    37.1s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 37.3s\nDownloading  (2) ━━━━━━━━━━━━━━╸━━━━━━━━  85.8MB pillow                    37.2s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s[+] 37.4s\nDownloading  (2) ━━━━━━━━━━━━━━╸━━━━━━━━  86.0MB pillow                    37.3s\nExtracting       ━━━━━━━━━━━━━━━━━━╸━━━━      12                            1.4s\n\n\n\n\nShow the code\nfrom fastcore.basics import patch\n\n\n\n\nShow the code\n??patch\n\n\n\nSignature: patch(f=None, *, as_prop=False, cls_method=False)\nSource:   \ndef patch(f=None, *, as_prop=False, cls_method=False):\n    \"Decorator: add `f` to the first parameter's class (based on f's type annotations)\"\n    if f is None: return partial(patch, as_prop=as_prop, cls_method=cls_method)\n    ann,glb,loc = get_annotations_ex(f)\n    cls = union2tuple(eval_type(ann.pop('cls') if cls_method else next(iter(ann.values())), glb, loc))\n    return patch_to(cls, as_prop=as_prop, cls_method=cls_method)(f)\nFile:      ~/micromamba/envs/fastai/lib/python3.11/site-packages/fastcore/basics.py\nType:      function\n\n\n\n\n\nShow the code\nfrom diffusers import StableDiffusionPipeline\n\nDEVICE='mps'\n\npipe = StableDiffusionPipeline.from_pretrained(\n    \"CompVis/stable-diffusion-v1-4\",\n    use_auth_token=True\n).to(DEVICE)\n\n\nCannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n```\npip install accelerate\n```\n.\n`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n\n\n\n\nShow the code\npip install accelerate\n\n\nCollecting accelerate\n  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 244.2/244.2 kB 1.1 MB/s eta 0:00:00a 0:00:01\nRequirement already satisfied: numpy&gt;=1.17 in /Users/kashmkj/micromamba/envs/fastai/lib/python3.11/site-packages (from accelerate) (1.23.5)\nRequirement already satisfied: packaging&gt;=20.0 in /Users/kashmkj/micromamba/envs/fastai/lib/python3.11/site-packages (from accelerate) (23.1)\nRequirement already satisfied: psutil in /Users/kashmkj/micromamba/envs/fastai/lib/python3.11/site-packages (from accelerate) (5.9.5)\nRequirement already satisfied: pyyaml in /Users/kashmkj/micromamba/envs/fastai/lib/python3.11/site-packages (from accelerate) (6.0)\nRequirement already satisfied: torch&gt;=1.10.0 in /Users/kashmkj/micromamba/envs/fastai/lib/python3.11/site-packages (from accelerate) (2.1.0.dev20230720)\nRequirement already satisfied: filelock in /Users/kashmkj/micromamba/envs/fastai/lib/python3.11/site-packages (from torch&gt;=1.10.0-&gt;accelerate) (3.12.0)\nRequirement already satisfied: typing-extensions in /Users/kashmkj/micromamba/envs/fastai/lib/python3.11/site-packages (from torch&gt;=1.10.0-&gt;accelerate) (4.5.0)\nRequirement already satisfied: sympy in /Users/kashmkj/micromamba/envs/fastai/lib/python3.11/site-packages (from torch&gt;=1.10.0-&gt;accelerate) (1.11.1)\nRequirement already satisfied: networkx in /Users/kashmkj/micromamba/envs/fastai/lib/python3.11/site-packages (from torch&gt;=1.10.0-&gt;accelerate) (3.1)\nRequirement already satisfied: jinja2 in /Users/kashmkj/micromamba/envs/fastai/lib/python3.11/site-packages (from torch&gt;=1.10.0-&gt;accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /Users/kashmkj/micromamba/envs/fastai/lib/python3.11/site-packages (from torch&gt;=1.10.0-&gt;accelerate) (2023.6.0)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in /Users/kashmkj/micromamba/envs/fastai/lib/python3.11/site-packages (from jinja2-&gt;torch&gt;=1.10.0-&gt;accelerate) (2.1.2)\nRequirement already satisfied: mpmath&gt;=0.19 in /Users/kashmkj/micromamba/envs/fastai/lib/python3.11/site-packages (from sympy-&gt;torch&gt;=1.10.0-&gt;accelerate) (1.3.0)\nInstalling collected packages: accelerate\nSuccessfully installed accelerate-0.21.0\nNote: you may need to restart the kernel to use updated packages."
  },
  {
    "objectID": "posts/HuggingFace/Stable_Diffusion_Mac_M2.html",
    "href": "posts/HuggingFace/Stable_Diffusion_Mac_M2.html",
    "title": "Train Stable Diffusion Model on Mac M1/M2 in under 3 minutes",
    "section": "",
    "text": "So readers, I don’t know why I chose to run a Stable Diffusion Model on my macbook Air M2, when there are already plenty of cloud based GPU options available, when myself, being very consciously aware that it would be a demanding process. Anywho, now that I decided to train the model on my mac, I am jotting down on how, after spending ~3 hours, I was able to run a pre-trained Stable Diffusion Model in under 2 minutes on my M2 Macbok Air. As always, let’s start with installing and importing the necessary libraries..\n\n\nCode\n!pip install -Uq diffusers\n\n\nSegue: The above command installs and upgrades diffusers library through Pip:\n-U: The -U flag stands for –upgrade, which means that if any of the specified packages are already installed, pip will upgrade them to the latest version.\n-q: The -q flag stands for –quiet, which makes the installation process less verbose by suppressing unnecessary output. It only displays essential progress information.\n\n\nCode\nfrom diffusers import StableDiffusionPipeline\nimport torch\nimport logging\n\nlogging.disable(logging.WARNING)\n\n\nAs already stated, I’m using Mac M2 for running the Stable Diffusion Model, it is imporant that we assign device to mps. MPS device enables high-performance training on GPU for MacOS devices with Metal programming framework. Learn more about it on the official Pytorch docs.\n\n\nCode\ndevice = \"mps\" if torch.backends.mps.is_built() else \"cpu\"\ntorch_dtype = torch.float16 if device == \"mps\" else torch.float32\n\n\nIn PyTorch, the torch.float16 command is used to convert tensor data to the 16-bit floating-point format, also known as “half-precision” or “float16.” Half-precision floating-point numbers occupy 16 bits of memory, which is half the size of the standard 32-bit single-precision floating-point format (torch.float32). The primary purpose of using torch.float16 is to reduce the memory footprint and improve computation speed, especially when working with deep learning models on hardware that supports hardware-accelerated float16 operations.\nNote: I also tried not to use torch.float16, however, that made the Pipeline execution extremely slow.\n\n\nCode\nprint(f'device: {device}, torch_dtype: {torch_dtype}')\n\n\ndevice: mps, torch_dtype: torch.float16"
  },
  {
    "objectID": "posts/HuggingFace/Stable_Diffusion_Mac_M2.html#whats-happening-here",
    "href": "posts/HuggingFace/Stable_Diffusion_Mac_M2.html#whats-happening-here",
    "title": "Train Stable Diffusion Model on Mac M1/M2 in under 3 minutes",
    "section": "",
    "text": "So readers, I don’t know why I chose to run a Stable Diffusion Model on my macbook Air M2, when there are already plenty of cloud based GPU options available, when myself, being very consciously aware that it would be a demanding process. Anywho, now that I decided to train the model on my mac, I am jotting down on how, after spending ~3 hours, I was able to run a pre-trained Stable Diffusion Model in under 2 minutes on my M2 Macbok Air. As always, let’s start with installing and importing the necessary libraries..\n\n\nCode\n!pip install -Uq diffusers\n\n\nSegue: The above command installs and upgrades diffusers library through Pip:\n-U: The -U flag stands for –upgrade, which means that if any of the specified packages are already installed, pip will upgrade them to the latest version.\n-q: The -q flag stands for –quiet, which makes the installation process less verbose by suppressing unnecessary output. It only displays essential progress information.\n\n\nCode\nfrom diffusers import StableDiffusionPipeline\nimport torch\nimport logging\n\nlogging.disable(logging.WARNING)\n\n\nAs already stated, I’m using Mac M2 for running the Stable Diffusion Model, it is imporant that we assign device to mps. MPS device enables high-performance training on GPU for MacOS devices with Metal programming framework. Learn more about it on the official Pytorch docs.\n\n\nCode\ndevice = \"mps\" if torch.backends.mps.is_built() else \"cpu\"\ntorch_dtype = torch.float16 if device == \"mps\" else torch.float32\n\n\nIn PyTorch, the torch.float16 command is used to convert tensor data to the 16-bit floating-point format, also known as “half-precision” or “float16.” Half-precision floating-point numbers occupy 16 bits of memory, which is half the size of the standard 32-bit single-precision floating-point format (torch.float32). The primary purpose of using torch.float16 is to reduce the memory footprint and improve computation speed, especially when working with deep learning models on hardware that supports hardware-accelerated float16 operations.\nNote: I also tried not to use torch.float16, however, that made the Pipeline execution extremely slow.\n\n\nCode\nprint(f'device: {device}, torch_dtype: {torch_dtype}')\n\n\ndevice: mps, torch_dtype: torch.float16"
  },
  {
    "objectID": "posts/HuggingFace/Stable_Diffusion_Mac_M2.html#the-stablediffusion-pipeline..",
    "href": "posts/HuggingFace/Stable_Diffusion_Mac_M2.html#the-stablediffusion-pipeline..",
    "title": "Train Stable Diffusion Model on Mac M1/M2 in under 3 minutes",
    "section": "The StableDiffusion Pipeline..",
    "text": "The StableDiffusion Pipeline..\nStable Diffusion has something called a Pipeline[1]. If you’re familiar with fast.ai, this is similar to what we call as fastai learner. The pipeline basically contains all the models, processing, inferencing, etc. One can save the pipeline, into the huggingface cloud (also called Hub). Learn more about diffusion inference pipeline[2].\nOne just need to provide the pre-trained model as repo-id present in the huggingface repo or a path to directory containing pipeline weights, train further and generate images of your choice. You can also save your own pipeline to the hub, for other people to use.\nSegue\n[1]. Many Hugging Face libraries (along with other libraries such as scikit-learn) use the concept of a “pipeline” to indicate a sequence of steps that when combined complete some task.\n[2]. Inference means, using the model to generate output (i.e., images here), as opposed to training (or fine-tuning) models using new data.\nHere, we will be using CompVis/stable-diffusion-v1-4 model to generate our image from the text prompt.\n\n\nCode\nmodel_id = \"CompVis/stable-diffusion-v1-4\"\npipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch_dtype)\npipe = pipe.to(device)\n\n\n\nWhat else did I try..\nFrom the limited yet somehow various articles I read, I tried running the pipeline by passing several different arguments to the StableDiffusionPipeline.from_pretrained(..) function. However, the above worked best for me. Some of the parameters I tried include:\npipe = StableDiffusionPipeline.from_pretrained(\n    \"CompVis/stable-diffusion-v1-4\",\n    use_auth_token=True,\n    revision=\"fp16\", \n    torch_dtype=torch.float16,\n    safety_checker=None\n).to(torch.device(\"mps\"))\npipe = StableDiffusionPipeline.from_pretrained(\n    \"CompVis/stable-diffusion-v1-4\",\n    use_auth_token=True,\n    safety_checker=None\n).to(torch.device(\"mps\"))\npipe = StableDiffusionPipeline.from_pretrained(\n    \"CompVis/stable-diffusion-v1-4\",\n    use_auth_token=True\n).to(torch.device(\"mps\"))\nAll the above three resulted in taking ~35 minutes of executing pipeline to generate an image (Present as part of the next code cell). With a few trial-and-errors, I was able to bring down the time from 30 minutes to under 2 minutes\nIt is recommended at multiple places including the official huggingface docs, that if your GPU is not big enough to use pipe command, run pipe.enable_attention_slicing()\nAs described in the docs: &gt; When this option is enabled, the attention module will split the input tensor in slices, to compute attention in several steps. This is useful to save some memory in exchange for a small speed decrease.\nBUT WAITTT!! Running the above command before executing the pipe operation to generate image(s) resulted in a completely blacked-out image. I tried various prompts and seeds to generate an image, however, it wasn’t successful on my machine. Hence, I didn’t use this command. If anyone is successfully able to generate an image by enabling the attention slicing mechanism, pls feel free to provide me information on how did you achieve that :)\n\n\nCode\ntorch.manual_seed(1024)\nprompt = [\"European interior design room\"]\nimages = pipe(prompt, num_images_per_prompt=1)[0]\n\n\n\n\n\n\n\nCode\ndisplay(images[0])\n\n\n\n\n\nAs you can see it took less than 3 minutes to generate the image. Albiet, the best I have reached so far is ~1:30 minutes when I had most of applications closed. I know, folks have been able to successfully generate images in under 30 seconds on Mac M1/M2 chips, but for me, this is the best as of today that I could achieve. In my opinion, this machine is the lowest verion of Macbook Air M2, hence, the trade-off. I will keep on updating this blog post as amd when I am able to optimise it further.\nHope the above walk-through helps someone who’s struggling to run stable diffusion pre-trained models on their Macbook machine.\nAhh and yes, don’t forget to upvote this blog if even a tiny ounce of it helped you in some progress, as they always say, an upvote a blog keeps the blogger happy and prompt :)"
  },
  {
    "objectID": "posts/HuggingFace/Stable_Diffusion_Mac_M2.html#thankyouuuusss",
    "href": "posts/HuggingFace/Stable_Diffusion_Mac_M2.html#thankyouuuusss",
    "title": "Train Stable Diffusion Model on Mac M1/M2 in under 3 minutes",
    "section": "Thankyouuuusss",
    "text": "Thankyouuuusss"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "kashish18.github.io",
    "section": "",
    "text": "Hugging Face - Stable Diffusion\n\n\n\n\n\n\n\nblogging\n\n\njupyter\n\n\nStable Diffusion\n\n\n\n\n\n\n\n\n\n\n\nJul 19, 2023\n\n\nKashish Mukheja\n\n\n\n\n\n\n  \n\n\n\n\nTrain Stable Diffusion Model on Mac M1/M2 in under 3 minutes\n\n\n\n\n\n\n\nblogging\n\n\njupyter\n\n\nStable Diffusion\n\n\nMacbook\n\n\n\n\n\n\n\n\n\n\n\n\nJul 19, 2023\n\n\nKashish Mukheja\n\n\n\n\n\n\n  \n\n\n\n\nNLP - Introduction\n\n\n\n\n\n\n\nblogging\n\n\njupyter\n\n\nNatural Language Processing\n\n\n\n\n\n\n\n\n\n\n\nJul 10, 2023\n\n\nKashish Mukheja\n\n\n\n\n\n\n  \n\n\n\n\nEncoding Columns in a DataFrame\n\n\n\n\n\n\n\nblogging\n\n\njupyter\n\n\nData Preprocessing\n\n\n\n\n\n\n\n\n\n\n\nJun 8, 2023\n\n\nKashish Mukheja\n\n\n\n\n\n\n  \n\n\n\n\nHandling Missing Values\n\n\n\n\n\n\n\nblogging\n\n\njupyter\n\n\nData Preprocessing\n\n\n\n\n\n\n\n\n\n\n\nMay 27, 2023\n\n\nKashish Mukheja\n\n\n\n\n\n\n  \n\n\n\n\nComputer Vision - Concepts\n\n\n\n\n\n\n\nblogging\n\n\njupyter\n\n\nComputer Vision\n\n\n\n\n\n\n\n\n\n\n\nMay 27, 2023\n\n\nKashish Mukheja\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nMay 24, 2023\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  }
]