[
  {
    "objectID": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html",
    "href": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html",
    "title": "Encoding Columns in a DataFrame",
    "section": "",
    "text": "There are several blogs already present that provide detail on OneHotEncoding, LabelEncoding, etc. This blog will strictly focus on Encoding 1 or multiple columns of the dataframe in a single go. To achieve this, we use sklearn’s ColumnTransformer API.\nLet’s start with Installing the necessary libraries.."
  },
  {
    "objectID": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html#this-blog-focuses-on-encoding-columns-in-a-dataframe",
    "href": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html#this-blog-focuses-on-encoding-columns-in-a-dataframe",
    "title": "Encoding Columns in a DataFrame",
    "section": "",
    "text": "There are several blogs already present that provide detail on OneHotEncoding, LabelEncoding, etc. This blog will strictly focus on Encoding 1 or multiple columns of the dataframe in a single go. To achieve this, we use sklearn’s ColumnTransformer API.\nLet’s start with Installing the necessary libraries.."
  },
  {
    "objectID": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html#installing-libraries",
    "href": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html#installing-libraries",
    "title": "Encoding Columns in a DataFrame",
    "section": "Installing Libraries",
    "text": "Installing Libraries\n\nimport pandas as pd\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OrdinalEncoder, OneHotEncoder"
  },
  {
    "objectID": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html#lets-create-a-dummy-dataframe",
    "href": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html#lets-create-a-dummy-dataframe",
    "title": "Encoding Columns in a DataFrame",
    "section": "Let’s create a dummy dataframe",
    "text": "Let’s create a dummy dataframe\nWe will create a dataframe name employee_df with columns field, salary, avg_years_of_exp, and gender_category. Column gender_category will have one of either Male/Female whichever has the highest proportion in that particular field.\n\nemployees_df = pd.DataFrame({\n    'field': ['Tech', 'Finance', 'HR', 'Marketing', 'Sales','BioTech'],\n    'salary': ['high', 'high', 'low', 'medium', 'medium', 'high'],\n    'avg_years_of_exp': [4, 6, 5, 8, 8, 10],\n    'gender_category': ['Male', 'Female', 'Female', 'Male', 'Male', 'Female'], # max(Male, Female) gender for each field  \n})\n\n\nfield, and gender_category are non-ordinal categorical features\nsalary is an ordinal categorical feature\navg_years_of_exp looks like a categorical feature as well, but when considering the bigger picture, where we would have thousands of records, and maybe in floating point data types, will not be treated as a categorical feature. We can create a year_experice_range column containing different range of experience (For E.g., 0-3, 4-6, etc.) and treat that as a categorical feature. But we will ignore that for now."
  },
  {
    "objectID": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html#creating-ordinal-feature-and-ordinalencoder",
    "href": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html#creating-ordinal-feature-and-ordinalencoder",
    "title": "Encoding Columns in a DataFrame",
    "section": "Creating Ordinal Feature and OrdinalEncoder",
    "text": "Creating Ordinal Feature and OrdinalEncoder\nOrdinal related to a column which can be thought of as a categorical one, but with a maintained sequencing or hierarchy. For instance, (1) Rank 1,2, or 3 ; (2) Salary as high, low, or medium; (3) height as tall, taller, tallest and so on.\n\nordinal_feature = ['salary']\nordinal_transformer = OrdinalEncoder()"
  },
  {
    "objectID": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html#creating-non-ordinal-feature-and-onehotencoder",
    "href": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html#creating-non-ordinal-feature-and-onehotencoder",
    "title": "Encoding Columns in a DataFrame",
    "section": "Creating Non Ordinal Feature and OneHotEncoder",
    "text": "Creating Non Ordinal Feature and OneHotEncoder\n\nnon_ordinal_categorical_features = ['field', 'gender_category']\nnon_ordinal_categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")"
  },
  {
    "objectID": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html#creating-column-transformer",
    "href": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html#creating-column-transformer",
    "title": "Encoding Columns in a DataFrame",
    "section": "Creating Column Transformer",
    "text": "Creating Column Transformer\nWe provide data for ordinal_transformer & non_ordinal_categorical_transformer\n\ncolumn_transformer = ColumnTransformer(transformers=[\n    ('ordinal', ordinal_transformer, ordinal_feature),\n    ('non_ordinal_category', non_ordinal_categorical_transformer, non_ordinal_categorical_features)],\n                                      remainder='drop')\n\n\nremainder='drop' will drop all the remaining columns which do not required to be transformed. If you want to keep the remaining columns as it is, you may provide remainder='passthrough\n\n\npd.DataFrame(column_transformer.fit_transform(employees_df))\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n\n0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n1.0\n\n\n1\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n2\n1.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n3\n2.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n1.0\n\n\n4\n2.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n1.0\n\n\n5\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n\n\n\n\n\nAs you can see, we are not really able to comprehend which column represents what value from the original dataframe. To compensate for it, we will just perform a couple of tweeks."
  },
  {
    "objectID": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html#creating-the-final-transformer-with-columns-intact-and-understandable",
    "href": "posts/Data-preprocessing-Feature-Engineering/column_encoding.html#creating-the-final-transformer-with-columns-intact-and-understandable",
    "title": "Encoding Columns in a DataFrame",
    "section": "Creating the final Transformer with Columns intact and understandable",
    "text": "Creating the final Transformer with Columns intact and understandable\n\nnon_ordinal_categorical_transformer = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\") # New code added\n\n# Note: sparse_output=False is required to preserve column orders and provide a prefix for the columns. \n\ncolumn_transformer = ColumnTransformer(transformers=[\n    ('ordinal', ordinal_transformer, ordinal_feature),\n    ('non_ordinal_category', non_ordinal_categorical_transformer, non_ordinal_categorical_features)],\n                                      remainder='drop') # This remains same\n\ncolumn_transformer.set_output(transform='pandas') # New code added\n\nColumnTransformer(transformers=[('ordinal', OrdinalEncoder(), ['salary']),\n                                ('non_ordinal_category',\n                                 OneHotEncoder(handle_unknown='ignore',\n                                               sparse_output=False),\n                                 ['field', 'gender_category'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.ColumnTransformerColumnTransformer(transformers=[('ordinal', OrdinalEncoder(), ['salary']),\n                                ('non_ordinal_category',\n                                 OneHotEncoder(handle_unknown='ignore',\n                                               sparse_output=False),\n                                 ['field', 'gender_category'])])ordinal['salary']OrdinalEncoderOrdinalEncoder()non_ordinal_category['field', 'gender_category']OneHotEncoderOneHotEncoder(handle_unknown='ignore', sparse_output=False)\n\n\n\ndf_pandas = column_transformer.fit_transform(employees_df)\ndf_pandas\n\n\n\n\n\n\n\n\nordinal__salary\nnon_ordinal_category__field_BioTech\nnon_ordinal_category__field_Finance\nnon_ordinal_category__field_HR\nnon_ordinal_category__field_Marketing\nnon_ordinal_category__field_Sales\nnon_ordinal_category__field_Tech\nnon_ordinal_category__gender_category_Female\nnon_ordinal_category__gender_category_Male\n\n\n\n\n0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n1.0\n\n\n1\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n2\n1.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n3\n2.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n1.0\n\n\n4\n2.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n1.0\n\n\n5\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0"
  },
  {
    "objectID": "posts/Data-preprocessing-Feature-Engineering/index.html",
    "href": "posts/Data-preprocessing-Feature-Engineering/index.html",
    "title": "Handling Missing Values",
    "section": "",
    "text": "A dataset can have columns containing null values, and these arise from 3 reasons : (1) Missing Complete at Random, (2) Missing at Random, (3) Missing Not at Random. Null values in case of (1) and (2) are not useful for insights and inferences, and should be replaced/imputed with some other value. The some other value depends on multiple factors. We will focus on numerical and categorical columns with missing values as part of the current blog.\nWe can hanlde missing values by any of the below techniques:\n\nDropping rows or columns - This can lead to missing out of valuable information in the data. Most often, not a suggested approach. Listwise Deletion, is another form of dropping rows containing missing values.\nReplacing missing values with mean or median, i.e., P50 (for continuous data) - Effect of outliers will can play a role in replacing with mean. Replacing the values with median, is a good option.\nReplacing missing values with mode (for categorical) - This is only for categorical , and may or may not work depending on the dataset you’re dealing with. This completely ignores the affect of features (i.e., feature importance and tree interpretation) have on the target variables.\nReplacing missing values using KNN model - The k nearest neighbor algorithm is often used to impute a missing value based on how closely it resembles the points in the training set. The non-null features are used to predict the features having null values\nMultiVariate Imputation - It suggests imputing the null values based on the other columns in the dataset. It therefore assumes that data (or features) with missing values have some sort of relation with the non-missing feature columns. This is also called Multiple Imputation by Chained Equation."
  },
  {
    "objectID": "posts/Data-preprocessing-Feature-Engineering/index.html#this-blog-focuses-on-handling-missing-values-in-the-dataframe.",
    "href": "posts/Data-preprocessing-Feature-Engineering/index.html#this-blog-focuses-on-handling-missing-values-in-the-dataframe.",
    "title": "Handling Missing Values",
    "section": "",
    "text": "A dataset can have columns containing null values, and these arise from 3 reasons : (1) Missing Complete at Random, (2) Missing at Random, (3) Missing Not at Random. Null values in case of (1) and (2) are not useful for insights and inferences, and should be replaced/imputed with some other value. The some other value depends on multiple factors. We will focus on numerical and categorical columns with missing values as part of the current blog.\nWe can hanlde missing values by any of the below techniques:\n\nDropping rows or columns - This can lead to missing out of valuable information in the data. Most often, not a suggested approach. Listwise Deletion, is another form of dropping rows containing missing values.\nReplacing missing values with mean or median, i.e., P50 (for continuous data) - Effect of outliers will can play a role in replacing with mean. Replacing the values with median, is a good option.\nReplacing missing values with mode (for categorical) - This is only for categorical , and may or may not work depending on the dataset you’re dealing with. This completely ignores the affect of features (i.e., feature importance and tree interpretation) have on the target variables.\nReplacing missing values using KNN model - The k nearest neighbor algorithm is often used to impute a missing value based on how closely it resembles the points in the training set. The non-null features are used to predict the features having null values\nMultiVariate Imputation - It suggests imputing the null values based on the other columns in the dataset. It therefore assumes that data (or features) with missing values have some sort of relation with the non-missing feature columns. This is also called Multiple Imputation by Chained Equation."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/NLP/index.html",
    "href": "posts/NLP/index.html",
    "title": "NLP - Introduction",
    "section": "",
    "text": "Natural Language Processing involves fetching text data in the form of prose or document, and perform classification or other text-based applications. Some top applications include:\n\nSentiment Analysis\nWhich author wrote what document\nLegal Document discovery -&gt; Is the legal document in scope or out scope.\nOrganising documents -&gt;\nTriaging inbound emails -&gt; This involves routing of the incoming emails to the user or a work queue, to either handle the email, or taking actions in other ways to help address issues reported in the email\n\nWe are going to use HuggingFace Transformers library. It has a medium level API, and thus provides flexibility to tweak. The library has really state-of-the-art models (similar to Timm for Computer Vision). For the current blog, we will be using a Kaggle dataset for US Patent Phrase to Phrase matching.\nWe will fine tune a pre-trained hugging face model\nSeque: Huggingface models are different than Timm in the sense that each of the models in hugging face, can be trained on different corpuses for solving different problems.\nUsing different libraries, help brush up the same concepts in different ways. For the current blog, we will be using some of the standard python libraries like pandas, numpy, pytorch & for performing NLP specific operations, we will be using Huggingface transformer library. So let’s setup the noteboook first.."
  },
  {
    "objectID": "posts/NLP/index.html#something-about-the-ulm-fit",
    "href": "posts/NLP/index.html#something-about-the-ulm-fit",
    "title": "NLP - Introduction",
    "section": "Something about the ULM-Fit",
    "text": "Something about the ULM-Fit\nThe above concept, was first introduced in architecture called ULM-Fit , which was developed by Jeremy Howard. So, the idea of the architecture was:\n\nTrain a Language model using wikipedia pages, to predict every next word of every wikipedia article\nCreated a second language model, by using the first language model, and ran a few more epochs on IMDB movie reviews.\nUsed the model, and finally built a classifier to categorize movie rating\n\nJargon: A language model is something that can predict the next word in a text"
  },
  {
    "objectID": "posts/NLP/index.html#something-about-training-a-text-data",
    "href": "posts/NLP/index.html#something-about-training-a-text-data",
    "title": "NLP - Introduction",
    "section": "Something about training a text data",
    "text": "Something about training a text data\nNeural networks work with numbers. We take some numbers, multiple with matrices, replace the -ves with 0 (i.e., ReLU activation) and repeat the process a few times. But how would we do that for strings ? This is done in a few steps: 1. Split the text into tokens. Tokens are basically words or single unit of text. 2. After splitting into words, we get a unique number for each unique word (called vocabulary). The bigger the vocabulary, more data we will need to train, and thus more storage will be occupied, leading to reduced computation. We don’t want that right :)\nFurthermore, some languages like Chinese don’t have spaces in between words. So, to overcome this problem, we tokenise into subwords (which is not heavily dependent on spaces). So, instead of dividing the corpuse based on spaces, subwords tokenization perform seperation based on group of characters that occur frequently together, and these become the vocabulary.\nNow, this tokenisation has different algorithms depending on the pre-trained models we use. Basically, how we tokenise a data ? -&gt; Every model has its own unique way to tokenise."
  },
  {
    "objectID": "posts/Computer-Vision-Concepts/index.html",
    "href": "posts/Computer-Vision-Concepts/index.html",
    "title": "Computer Vision - Concepts",
    "section": "",
    "text": "Pixel is the smallest fragment of an image."
  },
  {
    "objectID": "posts/Computer-Vision-Concepts/index.html#a-simple-cnn-architecture",
    "href": "posts/Computer-Vision-Concepts/index.html#a-simple-cnn-architecture",
    "title": "Computer Vision - Concepts",
    "section": "A Simple CNN Architecture",
    "text": "A Simple CNN Architecture\n\nWhat is inside a single convolution layer ?\n\nImage (RGB channels) is multiplied with (2) Kernel/Filters to produce a (3) convoluted matrix, also called feature map. This matrix is passed (4) to an activation function like ReLU to create an activation map, and (5) Pooling is applied on the resultant matrix. This new feature map will be input to the 2nd convolution layer.\n\nOnce the image has gone through N Convolution layers, it is flattened to feed into the fully connected neural network, which will then perform classification. Here, the learnable parameters weights are Filters. So, the filter weights are updated during backpropagation.\n\n\nWhat is Transfer Learning ?\nModel utilising the knowledge of a pre-trained model (which was trained for a task), to train a new similar task. Popularly used in both CNN, & NLP.\n\n\nShow the code\n%%latex\n\\begin{align}\n\\nabla \\cdot \\vec{\\mathbf{E}} & = 4 \\pi \\rho \\\\\n\\nabla \\times \\vec{\\mathbf{E}}\\, +\\, \\frac1c\\, \\frac{\\partial\\vec{\\mathbf{B}}}{\\partial t} & = \\vec{\\mathbf{0}} \\\\\n\\nabla \\cdot \\vec{\\mathbf{B}} & = 0\n\\end{align}\n\n\n\\[\\begin{align}\n\\nabla \\cdot \\vec{\\mathbf{E}} & = 4 \\pi \\rho \\\\\n\\nabla \\times \\vec{\\mathbf{E}}\\, +\\, \\frac1c\\, \\frac{\\partial\\vec{\\mathbf{B}}}{\\partial t} & = \\vec{\\mathbf{0}} \\\\\n\\nabla \\cdot \\vec{\\mathbf{B}} & = 0\n\\end{align}\\]\n\n\n\n\nShow the code\n9\n\n\n9\n\n\n\n\nShow the code\n%%latex\n\\begin{align}\n\\mathbf{B} & = 0\n\\end{align}\n\n\n\\[\\begin{align}\n\\{B} & = 0\n\\end{align}\\]"
  },
  {
    "objectID": "posts/HuggingFace/Stable_Diffusion_Mac_M2.html",
    "href": "posts/HuggingFace/Stable_Diffusion_Mac_M2.html",
    "title": "Train Stable Diffusion Model on Mac M1/M2 in under 3 minutes",
    "section": "",
    "text": "So readers, I don’t know why I chose to run a Stable Diffusion Model on my macbook Air M2, when there are already plenty of cloud based GPU options available, when myself, being very consciously aware that it would be a demanding process. Anywho, now that I decided to train the model on my mac, I am jotting down on how, after spending ~3 hours, I was able to run a pre-trained Stable Diffusion Model in under 2 minutes on my M2 Macbok Air. As always, let’s start with installing and importing the necessary libraries..\n\n\nCode\n!pip install -Uq diffusers\n\n\nSegue: The above command installs and upgrades diffusers library through Pip:\n-U: The -U flag stands for –upgrade, which means that if any of the specified packages are already installed, pip will upgrade them to the latest version.\n-q: The -q flag stands for –quiet, which makes the installation process less verbose by suppressing unnecessary output. It only displays essential progress information.\n\n\nCode\nfrom diffusers import StableDiffusionPipeline\nimport torch\nimport logging\n\nlogging.disable(logging.WARNING)\n\n\nAs already stated, I’m using Mac M2 for running the Stable Diffusion Model, it is imporant that we assign device to mps. MPS device enables high-performance training on GPU for MacOS devices with Metal programming framework. Learn more about it on the official Pytorch docs.\n\n\nCode\ndevice = \"mps\" if torch.backends.mps.is_built() else \"cpu\"\ntorch_dtype = torch.float16 if device == \"mps\" else torch.float32\n\n\nIn PyTorch, the torch.float16 command is used to convert tensor data to the 16-bit floating-point format, also known as “half-precision” or “float16.” Half-precision floating-point numbers occupy 16 bits of memory, which is half the size of the standard 32-bit single-precision floating-point format (torch.float32). The primary purpose of using torch.float16 is to reduce the memory footprint and improve computation speed, especially when working with deep learning models on hardware that supports hardware-accelerated float16 operations.\nNote: I also tried not to use torch.float16, however, that made the Pipeline execution extremely slow.\n\n\nCode\nprint(f'device: {device}, torch_dtype: {torch_dtype}')\n\n\ndevice: mps, torch_dtype: torch.float16"
  },
  {
    "objectID": "posts/HuggingFace/Stable_Diffusion_Mac_M2.html#whats-happening-here",
    "href": "posts/HuggingFace/Stable_Diffusion_Mac_M2.html#whats-happening-here",
    "title": "Train Stable Diffusion Model on Mac M1/M2 in under 3 minutes",
    "section": "",
    "text": "So readers, I don’t know why I chose to run a Stable Diffusion Model on my macbook Air M2, when there are already plenty of cloud based GPU options available, when myself, being very consciously aware that it would be a demanding process. Anywho, now that I decided to train the model on my mac, I am jotting down on how, after spending ~3 hours, I was able to run a pre-trained Stable Diffusion Model in under 2 minutes on my M2 Macbok Air. As always, let’s start with installing and importing the necessary libraries..\n\n\nCode\n!pip install -Uq diffusers\n\n\nSegue: The above command installs and upgrades diffusers library through Pip:\n-U: The -U flag stands for –upgrade, which means that if any of the specified packages are already installed, pip will upgrade them to the latest version.\n-q: The -q flag stands for –quiet, which makes the installation process less verbose by suppressing unnecessary output. It only displays essential progress information.\n\n\nCode\nfrom diffusers import StableDiffusionPipeline\nimport torch\nimport logging\n\nlogging.disable(logging.WARNING)\n\n\nAs already stated, I’m using Mac M2 for running the Stable Diffusion Model, it is imporant that we assign device to mps. MPS device enables high-performance training on GPU for MacOS devices with Metal programming framework. Learn more about it on the official Pytorch docs.\n\n\nCode\ndevice = \"mps\" if torch.backends.mps.is_built() else \"cpu\"\ntorch_dtype = torch.float16 if device == \"mps\" else torch.float32\n\n\nIn PyTorch, the torch.float16 command is used to convert tensor data to the 16-bit floating-point format, also known as “half-precision” or “float16.” Half-precision floating-point numbers occupy 16 bits of memory, which is half the size of the standard 32-bit single-precision floating-point format (torch.float32). The primary purpose of using torch.float16 is to reduce the memory footprint and improve computation speed, especially when working with deep learning models on hardware that supports hardware-accelerated float16 operations.\nNote: I also tried not to use torch.float16, however, that made the Pipeline execution extremely slow.\n\n\nCode\nprint(f'device: {device}, torch_dtype: {torch_dtype}')\n\n\ndevice: mps, torch_dtype: torch.float16"
  },
  {
    "objectID": "posts/HuggingFace/Stable_Diffusion_Mac_M2.html#the-stablediffusion-pipeline..",
    "href": "posts/HuggingFace/Stable_Diffusion_Mac_M2.html#the-stablediffusion-pipeline..",
    "title": "Train Stable Diffusion Model on Mac M1/M2 in under 3 minutes",
    "section": "The StableDiffusion Pipeline..",
    "text": "The StableDiffusion Pipeline..\nStable Diffusion has something called a Pipeline[1]. If you’re familiar with fast.ai, this is similar to what we call as fastai learner. The pipeline basically contains all the models, processing, inferencing, etc. One can save the pipeline, into the huggingface cloud (also called Hub). Learn more about diffusion inference pipeline[2].\nOne just need to provide the pre-trained model as repo-id present in the huggingface repo or a path to directory containing pipeline weights, train further and generate images of your choice. You can also save your own pipeline to the hub, for other people to use.\nSegue\n[1]. Many Hugging Face libraries (along with other libraries such as scikit-learn) use the concept of a “pipeline” to indicate a sequence of steps that when combined complete some task.\n[2]. Inference means, using the model to generate output (i.e., images here), as opposed to training (or fine-tuning) models using new data.\nHere, we will be using CompVis/stable-diffusion-v1-4 model to generate our image from the text prompt.\n\n\nCode\nmodel_id = \"CompVis/stable-diffusion-v1-4\"\npipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch_dtype)\npipe = pipe.to(device)\n\n\n\nWhat else did I try..\nFrom the limited yet somehow various articles I read, I tried running the pipeline by passing several different arguments to the StableDiffusionPipeline.from_pretrained(..) function. However, the above worked best for me. Some of the parameters I tried include:\npipe = StableDiffusionPipeline.from_pretrained(\n    \"CompVis/stable-diffusion-v1-4\",\n    use_auth_token=True,\n    revision=\"fp16\", \n    torch_dtype=torch.float16,\n    safety_checker=None\n).to(torch.device(\"mps\"))\npipe = StableDiffusionPipeline.from_pretrained(\n    \"CompVis/stable-diffusion-v1-4\",\n    use_auth_token=True,\n    safety_checker=None\n).to(torch.device(\"mps\"))\npipe = StableDiffusionPipeline.from_pretrained(\n    \"CompVis/stable-diffusion-v1-4\",\n    use_auth_token=True\n).to(torch.device(\"mps\"))\nAll the above three resulted in taking ~35 minutes of executing pipeline to generate an image (Present as part of the next code cell). With a few trial-and-errors, I was able to bring down the time from 30 minutes to under 2 minutes\nIt is recommended at multiple places including the official huggingface docs, that if your GPU is not big enough to use pipe command, run pipe.enable_attention_slicing()\nAs described in the docs: &gt; When this option is enabled, the attention module will split the input tensor in slices, to compute attention in several steps. This is useful to save some memory in exchange for a small speed decrease.\nBUT WAITTT!! Running the above command before executing the pipe operation to generate image(s) resulted in a completely blacked-out image. I tried various prompts and seeds to generate an image, however, it wasn’t successful on my machine. Hence, I didn’t use this command. If anyone is successfully able to generate an image by enabling the attention slicing mechanism, pls feel free to provide me information on how did you achieve that :)\n\n\nCode\ntorch.manual_seed(1024)\nprompt = [\"European interior design room\"]\nimages = pipe(prompt, num_images_per_prompt=1)[0]\n\n\n\n\n\n\n\nCode\ndisplay(images[0])\n\n\n\n\n\nAs you can see it took less than 3 minutes to generate the image. Albiet, the best I have reached so far is ~1:30 minutes when I had most of applications closed. I know, folks have been able to successfully generate images in under 30 seconds on Mac M1/M2 chips, but for me, this is the best as of today that I could achieve. In my opinion, this machine is the lowest verion of Macbook Air M2, hence, the trade-off. I will keep on updating this blog post as amd when I am able to optimise it further.\nHope the above walk-through helps someone who’s struggling to run stable diffusion pre-trained models on their Macbook machine.\nAhh and yes, don’t forget to upvote this blog if even a tiny ounce of it helped you in some progress, as they always say, an upvote a blog keeps the blogger happy and prompt :)"
  },
  {
    "objectID": "posts/HuggingFace/Stable_Diffusion_Mac_M2.html#thankyouuuusss",
    "href": "posts/HuggingFace/Stable_Diffusion_Mac_M2.html#thankyouuuusss",
    "title": "Train Stable Diffusion Model on Mac M1/M2 in under 3 minutes",
    "section": "Thankyouuuusss",
    "text": "Thankyouuuusss"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "kashish18.github.io",
    "section": "",
    "text": "Train Stable Diffusion Model on Mac M1/M2 in under 3 minutes\n\n\n\n\n\n\n\nblogging\n\n\njupyter\n\n\nStable Diffusion\n\n\nMacbook\n\n\n\n\n\n\n\n\n\n\n\n\nJul 19, 2023\n\n\nKashish Mukheja\n\n\n\n\n\n\n  \n\n\n\n\nNLP - Introduction\n\n\n\n\n\n\n\nblogging\n\n\njupyter\n\n\nNatural Language Processing\n\n\n\n\n\n\n\n\n\n\n\nJul 10, 2023\n\n\nKashish Mukheja\n\n\n\n\n\n\n  \n\n\n\n\nEncoding Columns in a DataFrame\n\n\n\n\n\n\n\nblogging\n\n\njupyter\n\n\nData Preprocessing\n\n\n\n\n\n\n\n\n\n\n\nJun 8, 2023\n\n\nKashish Mukheja\n\n\n\n\n\n\n  \n\n\n\n\nHandling Missing Values\n\n\n\n\n\n\n\nblogging\n\n\njupyter\n\n\nData Preprocessing\n\n\n\n\n\n\n\n\n\n\n\nMay 27, 2023\n\n\nKashish Mukheja\n\n\n\n\n\n\n  \n\n\n\n\nComputer Vision - Concepts\n\n\n\n\n\n\n\nblogging\n\n\njupyter\n\n\nComputer Vision\n\n\n\n\n\n\n\n\n\n\n\nMay 27, 2023\n\n\nKashish Mukheja\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nJupyter\n\n\n\n\n\n\n\n\n\n\n\nMay 24, 2023\n\n\nKashish Mukheja\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  }
]